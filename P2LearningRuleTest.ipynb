{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ceb77214",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neural import Perceptron, Activation\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2df40ad",
   "metadata": {},
   "source": [
    "## Training test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d6364f0",
   "metadata": {},
   "source": [
    "#### AND Gate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7067565e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE on epoch 1 0.5\n",
      "Perceptron(weights=[0.47244862689634937, 0.5342949589382112], bias=0.6023791264922815) \n",
      "\n",
      "MSE on epoch 2 0.5\n",
      "Perceptron(weights=[0.3724486268963494, 0.43429495893821124], bias=0.4023791264922816) \n",
      "\n",
      "MSE on epoch 3 0.5\n",
      "Perceptron(weights=[0.2724486268963494, 0.33429495893821126], bias=0.2023791264922816) \n",
      "\n",
      "MSE on epoch 4 0.5\n",
      "Perceptron(weights=[0.1724486268963494, 0.23429495893821126], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 5 0.75\n",
      "Perceptron(weights=[0.0724486268963494, 0.13429495893821125], bias=-0.19762087350771843) \n",
      "\n",
      "MSE on epoch 6 0.5\n",
      "Perceptron(weights=[0.0724486268963494, 0.13429495893821125], bias=-0.09762087350771842) \n",
      "\n",
      "MSE on epoch 7 0.75\n",
      "Perceptron(weights=[0.0724486268963494, 0.034294958938211245], bias=-0.09762087350771842) \n",
      "\n",
      "MSE on epoch 8 0.5\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=-0.09762087350771842) \n",
      "\n",
      "MSE on epoch 9 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 10 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 11 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 12 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 13 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 14 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 15 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 16 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 17 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 18 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 19 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 20 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 21 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 22 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 23 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 24 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 25 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 26 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 27 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 28 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 29 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 30 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 31 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 32 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 33 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 34 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 35 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 36 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 37 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 38 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 39 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 40 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 41 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 42 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 43 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 44 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 45 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 46 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 47 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 48 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 49 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 50 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 51 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 52 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 53 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 54 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 55 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 56 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 57 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 58 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 59 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 60 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 61 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 62 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 63 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 64 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 65 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 66 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 67 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 68 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 69 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 70 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 71 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 72 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 73 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 74 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 75 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 76 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 77 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 78 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 79 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 80 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 81 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 82 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 83 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 84 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 85 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 86 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 87 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 88 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 89 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 90 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 91 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 92 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 93 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 94 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 95 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 96 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 97 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 98 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 99 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 100 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 101 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 102 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 103 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 104 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 105 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 106 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 107 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 108 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 109 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 110 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 111 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 112 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 113 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 114 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 115 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 116 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 117 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 118 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 119 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 120 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 121 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 122 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 123 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 124 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 125 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 126 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 127 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 128 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 129 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 130 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 131 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 132 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 133 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 134 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 135 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 136 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 137 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 138 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 139 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 140 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 141 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 142 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 143 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 144 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 145 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 146 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 147 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 148 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 149 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 150 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 151 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 152 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 153 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 154 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 155 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 156 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 157 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 158 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 159 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 160 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 161 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 162 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 163 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 164 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 165 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 166 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 167 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 168 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 169 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 170 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 171 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 172 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 173 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 174 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 175 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 176 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 177 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 178 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 179 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 180 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 181 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 182 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 183 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 184 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 185 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 186 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 187 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 188 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 189 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 190 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 191 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 192 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 193 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 194 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 195 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 196 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 197 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 198 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 199 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 200 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 201 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 202 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 203 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 204 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 205 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 206 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 207 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 208 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 209 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 210 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 211 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 212 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 213 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 214 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 215 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 216 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 217 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 218 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 219 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 220 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 221 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 222 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 223 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 224 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 225 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 226 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 227 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 228 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 229 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 230 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 231 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 232 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 233 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 234 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 235 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 236 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 237 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 238 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 239 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 240 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 241 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 242 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 243 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 244 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 245 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 246 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 247 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 248 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 249 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 250 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 251 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 252 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 253 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 254 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 255 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 256 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 257 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 258 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 259 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 260 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 261 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 262 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 263 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 264 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 265 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 266 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 267 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 268 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 269 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 270 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 271 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 272 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 273 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 274 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 275 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 276 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 277 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 278 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 279 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 280 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 281 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 282 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 283 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 284 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 285 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 286 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 287 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 288 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 289 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 290 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 291 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 292 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 293 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 294 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 295 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 296 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 297 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 298 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 299 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 300 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 301 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 302 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 303 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 304 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 305 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 306 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 307 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 308 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 309 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 310 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 311 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 312 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 313 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 314 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 315 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 316 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 317 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 318 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 319 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 320 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 321 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 322 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 323 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 324 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 325 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 326 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 327 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 328 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 329 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 330 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 331 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 332 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 333 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 334 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 335 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 336 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 337 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 338 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 339 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 340 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 341 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 342 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 343 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 344 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 345 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 346 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 347 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 348 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 349 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 350 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 351 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 352 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 353 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 354 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 355 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 356 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 357 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 358 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 359 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 360 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 361 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 362 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 363 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 364 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 365 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 366 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 367 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 368 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 369 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 370 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 371 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 372 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 373 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 374 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 375 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 376 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 377 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 378 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 379 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 380 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 381 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 382 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 383 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 384 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 385 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 386 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 387 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 388 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 389 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 390 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 391 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 392 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 393 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 394 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 395 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 396 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 397 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 398 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 399 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 400 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 401 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 402 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 403 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 404 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 405 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 406 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 407 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 408 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 409 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 410 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 411 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 412 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 413 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 414 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 415 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 416 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 417 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 418 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 419 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 420 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 421 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 422 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 423 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 424 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 425 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 426 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 427 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 428 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 429 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 430 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 431 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 432 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 433 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 434 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 435 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 436 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 437 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 438 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 439 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 440 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 441 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 442 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 443 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 444 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 445 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 446 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 447 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 448 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 449 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 450 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 451 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 452 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 453 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 454 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 455 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 456 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 457 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 458 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 459 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 460 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 461 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 462 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 463 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 464 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 465 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 466 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 467 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 468 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 469 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 470 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 471 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 472 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 473 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 474 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 475 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 476 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 477 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 478 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 479 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 480 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 481 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 482 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 483 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 484 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 485 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 486 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 487 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 488 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 489 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 490 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 491 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 492 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 493 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 494 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 495 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 496 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 497 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 498 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 499 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 500 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 501 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 502 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 503 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 504 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 505 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 506 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 507 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 508 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 509 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 510 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 511 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 512 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 513 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 514 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 515 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 516 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 517 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 518 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 519 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 520 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 521 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 522 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 523 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 524 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 525 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 526 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 527 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 528 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 529 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 530 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 531 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 532 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 533 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 534 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 535 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 536 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 537 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 538 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 539 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 540 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 541 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 542 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 543 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 544 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 545 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 546 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 547 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 548 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 549 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 550 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 551 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 552 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 553 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 554 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 555 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 556 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 557 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 558 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 559 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 560 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 561 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 562 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 563 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 564 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 565 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 566 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 567 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 568 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 569 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 570 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 571 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 572 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 573 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 574 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 575 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 576 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 577 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 578 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 579 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 580 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 581 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 582 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 583 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 584 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 585 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 586 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 587 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 588 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 589 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 590 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 591 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 592 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 593 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 594 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 595 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 596 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 597 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 598 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 599 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 600 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 601 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 602 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 603 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 604 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 605 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 606 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 607 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 608 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 609 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 610 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 611 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 612 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 613 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 614 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 615 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 616 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 617 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 618 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 619 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 620 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 621 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 622 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 623 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 624 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 625 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 626 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 627 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 628 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 629 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 630 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 631 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 632 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 633 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 634 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 635 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 636 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 637 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 638 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 639 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 640 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 641 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 642 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 643 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 644 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 645 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 646 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 647 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 648 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 649 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 650 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 651 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 652 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 653 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 654 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 655 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 656 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 657 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 658 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 659 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 660 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 661 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 662 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 663 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 664 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 665 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 666 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 667 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 668 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 669 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 670 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 671 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 672 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 673 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 674 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 675 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 676 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 677 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 678 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 679 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 680 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 681 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 682 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 683 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 684 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 685 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 686 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 687 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 688 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 689 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 690 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 691 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 692 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 693 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 694 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 695 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 696 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 697 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 698 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 699 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 700 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 701 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 702 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 703 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 704 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 705 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 706 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 707 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 708 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 709 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 710 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 711 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 712 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 713 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 714 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 715 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 716 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 717 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 718 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 719 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 720 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 721 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 722 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 723 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 724 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 725 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 726 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 727 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 728 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 729 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 730 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 731 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 732 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 733 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 734 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 735 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 736 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 737 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 738 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 739 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 740 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 741 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 742 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 743 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 744 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 745 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 746 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 747 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 748 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 749 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 750 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 751 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 752 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 753 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 754 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 755 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 756 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 757 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 758 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 759 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 760 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 761 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 762 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 763 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 764 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 765 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 766 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 767 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 768 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 769 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 770 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 771 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 772 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 773 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 774 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 775 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 776 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 777 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 778 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 779 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 780 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 781 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 782 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 783 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 784 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 785 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 786 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 787 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 788 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 789 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 790 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 791 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 792 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 793 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 794 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 795 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 796 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 797 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 798 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 799 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 800 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 801 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 802 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 803 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 804 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 805 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 806 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 807 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 808 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 809 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 810 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 811 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 812 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 813 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 814 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 815 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 816 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 817 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 818 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 819 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 820 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 821 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 822 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 823 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 824 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 825 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 826 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 827 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 828 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 829 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 830 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 831 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 832 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 833 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 834 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 835 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 836 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 837 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 838 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 839 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 840 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 841 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 842 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 843 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 844 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 845 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 846 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 847 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 848 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 849 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 850 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 851 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 852 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 853 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 854 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 855 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 856 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 857 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 858 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 859 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 860 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 861 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 862 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 863 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 864 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 865 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 866 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 867 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 868 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 869 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 870 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 871 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 872 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 873 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 874 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 875 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 876 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 877 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 878 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 879 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 880 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 881 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 882 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 883 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 884 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 885 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 886 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 887 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 888 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 889 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 890 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 891 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 892 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 893 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 894 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 895 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 896 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 897 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 898 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 899 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 900 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 901 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 902 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 903 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 904 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 905 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 906 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 907 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 908 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 909 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 910 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 911 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 912 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 913 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 914 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 915 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 916 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 917 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 918 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 919 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 920 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 921 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 922 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 923 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 924 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 925 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 926 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 927 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 928 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 929 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 930 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 931 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 932 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 933 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 934 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 935 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 936 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 937 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 938 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 939 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 940 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 941 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 942 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 943 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 944 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 945 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 946 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 947 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 948 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 949 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 950 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 951 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 952 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 953 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 954 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 955 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 956 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 957 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 958 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 959 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 960 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 961 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 962 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 963 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 964 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 965 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 966 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 967 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 968 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 969 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 970 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 971 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 972 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 973 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 974 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 975 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 976 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 977 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 978 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 979 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 980 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 981 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 982 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 983 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 984 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 985 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 986 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 987 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 988 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 989 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 990 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 991 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 992 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 993 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 994 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 995 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 996 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 997 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 998 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 999 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "MSE on epoch 1000 0.75\n",
      "Perceptron(weights=[-0.027551373103650606, 0.034294958938211245], bias=0.002379126492281586) \n",
      "\n",
      "Input: [0, 0] Target: 0 Output: 1\n",
      "Input: [0, 1] Target: 1 Output: 1\n",
      "Input: [1, 0] Target: 1 Output: 0\n",
      "Input: [1, 1] Target: 0 Output: 1\n",
      "Weights: [-0.027551373103650606, 0.034294958938211245], Bias: 0.002379126492281586\n"
     ]
    }
   ],
   "source": [
    "perceptron = Perceptron(weights=[random.uniform(-1, 1) for _ in range(2)], bias=random.uniform(-1, 1))\n",
    "\n",
    "# Define the training data for the AND gate\n",
    "and_data = [([0, 0], 0), ([0, 1], 0), ([1, 0], 0), ([1, 1], 1)]\n",
    "\n",
    "# Train the Perceptron\n",
    "epochs = 1000\n",
    "for i in range(epochs):\n",
    "    for input, target in and_data:\n",
    "        perceptron.update(input, target)\n",
    "    mse = perceptron.loss(and_data)\n",
    "    print(\"MSE on epoch\", str(i+1), str(mse))\n",
    "    print(perceptron, '\\n')\n",
    "    if(mse == 0):\n",
    "        print(\"Learned after\", i, \"epochs\")\n",
    "        break\n",
    "\n",
    "# Test the Perceptron on the AND gate data\n",
    "for input, target in and_data:\n",
    "    output = perceptron.activate(input)\n",
    "    print(f\"Input: {input} Target: {target} Output: {output}\")\n",
    "\n",
    "# Print the final parameters of the Perceptron\n",
    "print(f\"Weights: {perceptron.weights}, Bias: {perceptron.bias}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d94425e",
   "metadata": {},
   "source": [
    "#### XOR Gate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1b9cebb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE on epoch 1 0.5\n",
      "MSE on epoch 2 0.5\n",
      "MSE on epoch 3 0.25\n",
      "MSE on epoch 4 0.25\n",
      "MSE on epoch 5 0.25\n",
      "MSE on epoch 6 0.25\n",
      "MSE on epoch 7 0.25\n",
      "MSE on epoch 8 0.5\n",
      "MSE on epoch 9 0.5\n",
      "MSE on epoch 10 0.5\n",
      "MSE on epoch 11 0.5\n",
      "MSE on epoch 12 0.5\n",
      "MSE on epoch 13 0.5\n",
      "MSE on epoch 14 0.5\n",
      "MSE on epoch 15 0.5\n",
      "MSE on epoch 16 0.5\n",
      "MSE on epoch 17 0.5\n",
      "MSE on epoch 18 0.5\n",
      "MSE on epoch 19 0.5\n",
      "MSE on epoch 20 0.5\n",
      "MSE on epoch 21 0.5\n",
      "MSE on epoch 22 0.5\n",
      "MSE on epoch 23 0.5\n",
      "MSE on epoch 24 0.5\n",
      "MSE on epoch 25 0.5\n",
      "MSE on epoch 26 0.5\n",
      "MSE on epoch 27 0.5\n",
      "MSE on epoch 28 0.5\n",
      "MSE on epoch 29 0.5\n",
      "MSE on epoch 30 0.5\n",
      "MSE on epoch 31 0.5\n",
      "MSE on epoch 32 0.5\n",
      "MSE on epoch 33 0.5\n",
      "MSE on epoch 34 0.5\n",
      "MSE on epoch 35 0.5\n",
      "MSE on epoch 36 0.5\n",
      "MSE on epoch 37 0.5\n",
      "MSE on epoch 38 0.5\n",
      "MSE on epoch 39 0.5\n",
      "MSE on epoch 40 0.5\n",
      "MSE on epoch 41 0.5\n",
      "MSE on epoch 42 0.5\n",
      "MSE on epoch 43 0.5\n",
      "MSE on epoch 44 0.5\n",
      "MSE on epoch 45 0.5\n",
      "MSE on epoch 46 0.5\n",
      "MSE on epoch 47 0.5\n",
      "MSE on epoch 48 0.5\n",
      "MSE on epoch 49 0.5\n",
      "MSE on epoch 50 0.5\n",
      "MSE on epoch 51 0.5\n",
      "MSE on epoch 52 0.5\n",
      "MSE on epoch 53 0.5\n",
      "MSE on epoch 54 0.5\n",
      "MSE on epoch 55 0.5\n",
      "MSE on epoch 56 0.5\n",
      "MSE on epoch 57 0.5\n",
      "MSE on epoch 58 0.5\n",
      "MSE on epoch 59 0.5\n",
      "MSE on epoch 60 0.5\n",
      "MSE on epoch 61 0.5\n",
      "MSE on epoch 62 0.5\n",
      "MSE on epoch 63 0.5\n",
      "MSE on epoch 64 0.5\n",
      "MSE on epoch 65 0.5\n",
      "MSE on epoch 66 0.5\n",
      "MSE on epoch 67 0.5\n",
      "MSE on epoch 68 0.5\n",
      "MSE on epoch 69 0.5\n",
      "MSE on epoch 70 0.5\n",
      "MSE on epoch 71 0.5\n",
      "MSE on epoch 72 0.5\n",
      "MSE on epoch 73 0.5\n",
      "MSE on epoch 74 0.5\n",
      "MSE on epoch 75 0.5\n",
      "MSE on epoch 76 0.5\n",
      "MSE on epoch 77 0.5\n",
      "MSE on epoch 78 0.5\n",
      "MSE on epoch 79 0.5\n",
      "MSE on epoch 80 0.5\n",
      "MSE on epoch 81 0.5\n",
      "MSE on epoch 82 0.5\n",
      "MSE on epoch 83 0.5\n",
      "MSE on epoch 84 0.5\n",
      "MSE on epoch 85 0.5\n",
      "MSE on epoch 86 0.5\n",
      "MSE on epoch 87 0.5\n",
      "MSE on epoch 88 0.5\n",
      "MSE on epoch 89 0.5\n",
      "MSE on epoch 90 0.5\n",
      "MSE on epoch 91 0.5\n",
      "MSE on epoch 92 0.5\n",
      "MSE on epoch 93 0.5\n",
      "MSE on epoch 94 0.5\n",
      "MSE on epoch 95 0.5\n",
      "MSE on epoch 96 0.5\n",
      "MSE on epoch 97 0.5\n",
      "MSE on epoch 98 0.5\n",
      "MSE on epoch 99 0.5\n",
      "MSE on epoch 100 0.5\n",
      "Input: [0, 0] Target: 0 Output: 1\n",
      "Input: [0, 1] Target: 1 Output: 1\n",
      "Input: [1, 0] Target: 1 Output: 0\n",
      "Input: [1, 1] Target: 0 Output: 0\n",
      "Weights: [-0.20222322715476346, 0.05596292254172225], Bias: 0.02611905420946911\n"
     ]
    }
   ],
   "source": [
    "perceptron = Perceptron(weights=[random.uniform(-1, 1) for _ in range(2)], bias=random.uniform(-1, 1))\n",
    "\n",
    "# Define the training data for the XOR gate\n",
    "and_data = [([0, 0], 0), ([0, 1], 1), ([1, 0], 1), ([1, 1], 0)]\n",
    "\n",
    "# Train the Perceptron\n",
    "epochs = 100\n",
    "for i in range(epochs):\n",
    "    for input, target in and_data:\n",
    "        perceptron.update(input, target)\n",
    "    mse = perceptron.loss(and_data)\n",
    "    print(\"MSE on epoch\", str(i+1), str(mse))\n",
    "    if(mse == 0):\n",
    "        print(\"Learned after\", i, \"epochs\")\n",
    "        break\n",
    "\n",
    "# Test the Perceptron on the XOR gate data\n",
    "for input, target in and_data:\n",
    "    output = perceptron.activate(input)\n",
    "    print(f\"Input: {input} Target: {target} Output: {output}\")\n",
    "\n",
    "# Print the final parameters of the Perceptron\n",
    "print(f\"Weights: {perceptron.weights}, Bias: {perceptron.bias}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e235d7b",
   "metadata": {},
   "source": [
    "#### IRIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c364887f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[5.1, 3.5, 1.4, 0.2],\n",
       "        [4.9, 3. , 1.4, 0.2],\n",
       "        [4.7, 3.2, 1.3, 0.2],\n",
       "        [4.6, 3.1, 1.5, 0.2],\n",
       "        [5. , 3.6, 1.4, 0.2],\n",
       "        [5.4, 3.9, 1.7, 0.4],\n",
       "        [4.6, 3.4, 1.4, 0.3],\n",
       "        [5. , 3.4, 1.5, 0.2],\n",
       "        [4.4, 2.9, 1.4, 0.2],\n",
       "        [4.9, 3.1, 1.5, 0.1],\n",
       "        [5.4, 3.7, 1.5, 0.2],\n",
       "        [4.8, 3.4, 1.6, 0.2],\n",
       "        [4.8, 3. , 1.4, 0.1],\n",
       "        [4.3, 3. , 1.1, 0.1],\n",
       "        [5.8, 4. , 1.2, 0.2],\n",
       "        [5.7, 4.4, 1.5, 0.4],\n",
       "        [5.4, 3.9, 1.3, 0.4],\n",
       "        [5.1, 3.5, 1.4, 0.3],\n",
       "        [5.7, 3.8, 1.7, 0.3],\n",
       "        [5.1, 3.8, 1.5, 0.3],\n",
       "        [5.4, 3.4, 1.7, 0.2],\n",
       "        [5.1, 3.7, 1.5, 0.4],\n",
       "        [4.6, 3.6, 1. , 0.2],\n",
       "        [5.1, 3.3, 1.7, 0.5],\n",
       "        [4.8, 3.4, 1.9, 0.2],\n",
       "        [5. , 3. , 1.6, 0.2],\n",
       "        [5. , 3.4, 1.6, 0.4],\n",
       "        [5.2, 3.5, 1.5, 0.2],\n",
       "        [5.2, 3.4, 1.4, 0.2],\n",
       "        [4.7, 3.2, 1.6, 0.2],\n",
       "        [4.8, 3.1, 1.6, 0.2],\n",
       "        [5.4, 3.4, 1.5, 0.4],\n",
       "        [5.2, 4.1, 1.5, 0.1],\n",
       "        [5.5, 4.2, 1.4, 0.2],\n",
       "        [4.9, 3.1, 1.5, 0.2],\n",
       "        [5. , 3.2, 1.2, 0.2],\n",
       "        [5.5, 3.5, 1.3, 0.2],\n",
       "        [4.9, 3.6, 1.4, 0.1],\n",
       "        [4.4, 3. , 1.3, 0.2],\n",
       "        [5.1, 3.4, 1.5, 0.2],\n",
       "        [5. , 3.5, 1.3, 0.3],\n",
       "        [4.5, 2.3, 1.3, 0.3],\n",
       "        [4.4, 3.2, 1.3, 0.2],\n",
       "        [5. , 3.5, 1.6, 0.6],\n",
       "        [5.1, 3.8, 1.9, 0.4],\n",
       "        [4.8, 3. , 1.4, 0.3],\n",
       "        [5.1, 3.8, 1.6, 0.2],\n",
       "        [4.6, 3.2, 1.4, 0.2],\n",
       "        [5.3, 3.7, 1.5, 0.2],\n",
       "        [5. , 3.3, 1.4, 0.2],\n",
       "        [7. , 3.2, 4.7, 1.4],\n",
       "        [6.4, 3.2, 4.5, 1.5],\n",
       "        [6.9, 3.1, 4.9, 1.5],\n",
       "        [5.5, 2.3, 4. , 1.3],\n",
       "        [6.5, 2.8, 4.6, 1.5],\n",
       "        [5.7, 2.8, 4.5, 1.3],\n",
       "        [6.3, 3.3, 4.7, 1.6],\n",
       "        [4.9, 2.4, 3.3, 1. ],\n",
       "        [6.6, 2.9, 4.6, 1.3],\n",
       "        [5.2, 2.7, 3.9, 1.4],\n",
       "        [5. , 2. , 3.5, 1. ],\n",
       "        [5.9, 3. , 4.2, 1.5],\n",
       "        [6. , 2.2, 4. , 1. ],\n",
       "        [6.1, 2.9, 4.7, 1.4],\n",
       "        [5.6, 2.9, 3.6, 1.3],\n",
       "        [6.7, 3.1, 4.4, 1.4],\n",
       "        [5.6, 3. , 4.5, 1.5],\n",
       "        [5.8, 2.7, 4.1, 1. ],\n",
       "        [6.2, 2.2, 4.5, 1.5],\n",
       "        [5.6, 2.5, 3.9, 1.1],\n",
       "        [5.9, 3.2, 4.8, 1.8],\n",
       "        [6.1, 2.8, 4. , 1.3],\n",
       "        [6.3, 2.5, 4.9, 1.5],\n",
       "        [6.1, 2.8, 4.7, 1.2],\n",
       "        [6.4, 2.9, 4.3, 1.3],\n",
       "        [6.6, 3. , 4.4, 1.4],\n",
       "        [6.8, 2.8, 4.8, 1.4],\n",
       "        [6.7, 3. , 5. , 1.7],\n",
       "        [6. , 2.9, 4.5, 1.5],\n",
       "        [5.7, 2.6, 3.5, 1. ],\n",
       "        [5.5, 2.4, 3.8, 1.1],\n",
       "        [5.5, 2.4, 3.7, 1. ],\n",
       "        [5.8, 2.7, 3.9, 1.2],\n",
       "        [6. , 2.7, 5.1, 1.6],\n",
       "        [5.4, 3. , 4.5, 1.5],\n",
       "        [6. , 3.4, 4.5, 1.6],\n",
       "        [6.7, 3.1, 4.7, 1.5],\n",
       "        [6.3, 2.3, 4.4, 1.3],\n",
       "        [5.6, 3. , 4.1, 1.3],\n",
       "        [5.5, 2.5, 4. , 1.3],\n",
       "        [5.5, 2.6, 4.4, 1.2],\n",
       "        [6.1, 3. , 4.6, 1.4],\n",
       "        [5.8, 2.6, 4. , 1.2],\n",
       "        [5. , 2.3, 3.3, 1. ],\n",
       "        [5.6, 2.7, 4.2, 1.3],\n",
       "        [5.7, 3. , 4.2, 1.2],\n",
       "        [5.7, 2.9, 4.2, 1.3],\n",
       "        [6.2, 2.9, 4.3, 1.3],\n",
       "        [5.1, 2.5, 3. , 1.1],\n",
       "        [5.7, 2.8, 4.1, 1.3],\n",
       "        [6.3, 3.3, 6. , 2.5],\n",
       "        [5.8, 2.7, 5.1, 1.9],\n",
       "        [7.1, 3. , 5.9, 2.1],\n",
       "        [6.3, 2.9, 5.6, 1.8],\n",
       "        [6.5, 3. , 5.8, 2.2],\n",
       "        [7.6, 3. , 6.6, 2.1],\n",
       "        [4.9, 2.5, 4.5, 1.7],\n",
       "        [7.3, 2.9, 6.3, 1.8],\n",
       "        [6.7, 2.5, 5.8, 1.8],\n",
       "        [7.2, 3.6, 6.1, 2.5],\n",
       "        [6.5, 3.2, 5.1, 2. ],\n",
       "        [6.4, 2.7, 5.3, 1.9],\n",
       "        [6.8, 3. , 5.5, 2.1],\n",
       "        [5.7, 2.5, 5. , 2. ],\n",
       "        [5.8, 2.8, 5.1, 2.4],\n",
       "        [6.4, 3.2, 5.3, 2.3],\n",
       "        [6.5, 3. , 5.5, 1.8],\n",
       "        [7.7, 3.8, 6.7, 2.2],\n",
       "        [7.7, 2.6, 6.9, 2.3],\n",
       "        [6. , 2.2, 5. , 1.5],\n",
       "        [6.9, 3.2, 5.7, 2.3],\n",
       "        [5.6, 2.8, 4.9, 2. ],\n",
       "        [7.7, 2.8, 6.7, 2. ],\n",
       "        [6.3, 2.7, 4.9, 1.8],\n",
       "        [6.7, 3.3, 5.7, 2.1],\n",
       "        [7.2, 3.2, 6. , 1.8],\n",
       "        [6.2, 2.8, 4.8, 1.8],\n",
       "        [6.1, 3. , 4.9, 1.8],\n",
       "        [6.4, 2.8, 5.6, 2.1],\n",
       "        [7.2, 3. , 5.8, 1.6],\n",
       "        [7.4, 2.8, 6.1, 1.9],\n",
       "        [7.9, 3.8, 6.4, 2. ],\n",
       "        [6.4, 2.8, 5.6, 2.2],\n",
       "        [6.3, 2.8, 5.1, 1.5],\n",
       "        [6.1, 2.6, 5.6, 1.4],\n",
       "        [7.7, 3. , 6.1, 2.3],\n",
       "        [6.3, 3.4, 5.6, 2.4],\n",
       "        [6.4, 3.1, 5.5, 1.8],\n",
       "        [6. , 3. , 4.8, 1.8],\n",
       "        [6.9, 3.1, 5.4, 2.1],\n",
       "        [6.7, 3.1, 5.6, 2.4],\n",
       "        [6.9, 3.1, 5.1, 2.3],\n",
       "        [5.8, 2.7, 5.1, 1.9],\n",
       "        [6.8, 3.2, 5.9, 2.3],\n",
       "        [6.7, 3.3, 5.7, 2.5],\n",
       "        [6.7, 3. , 5.2, 2.3],\n",
       "        [6.3, 2.5, 5. , 1.9],\n",
       "        [6.5, 3. , 5.2, 2. ],\n",
       "        [6.2, 3.4, 5.4, 2.3],\n",
       "        [5.9, 3. , 5.1, 1.8]]),\n",
       " 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]),\n",
       " 'frame': None,\n",
       " 'target_names': array(['setosa', 'versicolor', 'virginica'], dtype='<U10'),\n",
       " 'DESCR': '.. _iris_dataset:\\n\\nIris plants dataset\\n--------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 150 (50 in each of three classes)\\n    :Number of Attributes: 4 numeric, predictive attributes and the class\\n    :Attribute Information:\\n        - sepal length in cm\\n        - sepal width in cm\\n        - petal length in cm\\n        - petal width in cm\\n        - class:\\n                - Iris-Setosa\\n                - Iris-Versicolour\\n                - Iris-Virginica\\n                \\n    :Summary Statistics:\\n\\n    ============== ==== ==== ======= ===== ====================\\n                    Min  Max   Mean    SD   Class Correlation\\n    ============== ==== ==== ======= ===== ====================\\n    sepal length:   4.3  7.9   5.84   0.83    0.7826\\n    sepal width:    2.0  4.4   3.05   0.43   -0.4194\\n    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\\n    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\\n    ============== ==== ==== ======= ===== ====================\\n\\n    :Missing Attribute Values: None\\n    :Class Distribution: 33.3% for each of 3 classes.\\n    :Creator: R.A. Fisher\\n    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\\n    :Date: July, 1988\\n\\nThe famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\\nfrom Fisher\\'s paper. Note that it\\'s the same as in R, but not as in the UCI\\nMachine Learning Repository, which has two wrong data points.\\n\\nThis is perhaps the best known database to be found in the\\npattern recognition literature.  Fisher\\'s paper is a classic in the field and\\nis referenced frequently to this day.  (See Duda & Hart, for example.)  The\\ndata set contains 3 classes of 50 instances each, where each class refers to a\\ntype of iris plant.  One class is linearly separable from the other 2; the\\nlatter are NOT linearly separable from each other.\\n\\n.. topic:: References\\n\\n   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\\n     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\\n     Mathematical Statistics\" (John Wiley, NY, 1950).\\n   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\\n     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\\n   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\\n     Structure and Classification Rule for Recognition in Partially Exposed\\n     Environments\".  IEEE Transactions on Pattern Analysis and Machine\\n     Intelligence, Vol. PAMI-2, No. 1, 67-71.\\n   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\\n     on Information Theory, May 1972, 431-433.\\n   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\\n     conceptual clustering system finds 3 classes in the data.\\n   - Many, many more ...',\n",
       " 'feature_names': ['sepal length (cm)',\n",
       "  'sepal width (cm)',\n",
       "  'petal length (cm)',\n",
       "  'petal width (cm)'],\n",
       " 'filename': 'iris.csv',\n",
       " 'data_module': 'sklearn.datasets.data'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "iris = load_iris()\n",
    "\n",
    "random.seed(1704808)\n",
    "\n",
    "iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ea665a48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows  5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                  5.1               3.5                1.4               0.2   \n",
       "1                  4.9               3.0                1.4               0.2   \n",
       "2                  4.7               3.2                1.3               0.2   \n",
       "3                  4.6               3.1                1.5               0.2   \n",
       "4                  5.0               3.6                1.4               0.2   \n",
       "..                 ...               ...                ...               ...   \n",
       "145                6.7               3.0                5.2               2.3   \n",
       "146                6.3               2.5                5.0               1.9   \n",
       "147                6.5               3.0                5.2               2.0   \n",
       "148                6.2               3.4                5.4               2.3   \n",
       "149                5.9               3.0                5.1               1.8   \n",
       "\n",
       "     target  \n",
       "0       0.0  \n",
       "1       0.0  \n",
       "2       0.0  \n",
       "3       0.0  \n",
       "4       0.0  \n",
       "..      ...  \n",
       "145     2.0  \n",
       "146     2.0  \n",
       "147     2.0  \n",
       "148     2.0  \n",
       "149     2.0  \n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(data= np.c_[iris['data'], iris['target']],\n",
    "                     columns= iris['feature_names'] + ['target'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b9b437f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE on epoch 1 0.5\n",
      "MSE on epoch 2 0.5\n",
      "MSE on epoch 3 0.5\n",
      "MSE on epoch 4 0.5\n",
      "MSE on epoch 5 0.5\n",
      "MSE on epoch 6 0.0\n",
      "Learned after 5 epochs\n",
      "Input: [5.1, 3.5, 1.4, 0.2] Target: 0.0 Output: 0\n",
      "Input: [4.9, 3.0, 1.4, 0.2] Target: 0.0 Output: 0\n",
      "Input: [4.7, 3.2, 1.3, 0.2] Target: 0.0 Output: 0\n",
      "Input: [4.6, 3.1, 1.5, 0.2] Target: 0.0 Output: 0\n",
      "Input: [5.0, 3.6, 1.4, 0.2] Target: 0.0 Output: 0\n",
      "Input: [5.4, 3.9, 1.7, 0.4] Target: 0.0 Output: 0\n",
      "Input: [4.6, 3.4, 1.4, 0.3] Target: 0.0 Output: 0\n",
      "Input: [5.0, 3.4, 1.5, 0.2] Target: 0.0 Output: 0\n",
      "Input: [4.4, 2.9, 1.4, 0.2] Target: 0.0 Output: 0\n",
      "Input: [4.9, 3.1, 1.5, 0.1] Target: 0.0 Output: 0\n",
      "Input: [5.4, 3.7, 1.5, 0.2] Target: 0.0 Output: 0\n",
      "Input: [4.8, 3.4, 1.6, 0.2] Target: 0.0 Output: 0\n",
      "Input: [4.8, 3.0, 1.4, 0.1] Target: 0.0 Output: 0\n",
      "Input: [4.3, 3.0, 1.1, 0.1] Target: 0.0 Output: 0\n",
      "Input: [5.8, 4.0, 1.2, 0.2] Target: 0.0 Output: 0\n",
      "Input: [5.7, 4.4, 1.5, 0.4] Target: 0.0 Output: 0\n",
      "Input: [5.4, 3.9, 1.3, 0.4] Target: 0.0 Output: 0\n",
      "Input: [5.1, 3.5, 1.4, 0.3] Target: 0.0 Output: 0\n",
      "Input: [5.7, 3.8, 1.7, 0.3] Target: 0.0 Output: 0\n",
      "Input: [5.1, 3.8, 1.5, 0.3] Target: 0.0 Output: 0\n",
      "Input: [5.4, 3.4, 1.7, 0.2] Target: 0.0 Output: 0\n",
      "Input: [5.1, 3.7, 1.5, 0.4] Target: 0.0 Output: 0\n",
      "Input: [4.6, 3.6, 1.0, 0.2] Target: 0.0 Output: 0\n",
      "Input: [5.1, 3.3, 1.7, 0.5] Target: 0.0 Output: 0\n",
      "Input: [4.8, 3.4, 1.9, 0.2] Target: 0.0 Output: 0\n",
      "Input: [5.0, 3.0, 1.6, 0.2] Target: 0.0 Output: 0\n",
      "Input: [5.0, 3.4, 1.6, 0.4] Target: 0.0 Output: 0\n",
      "Input: [5.2, 3.5, 1.5, 0.2] Target: 0.0 Output: 0\n",
      "Input: [5.2, 3.4, 1.4, 0.2] Target: 0.0 Output: 0\n",
      "Input: [4.7, 3.2, 1.6, 0.2] Target: 0.0 Output: 0\n",
      "Input: [4.8, 3.1, 1.6, 0.2] Target: 0.0 Output: 0\n",
      "Input: [5.4, 3.4, 1.5, 0.4] Target: 0.0 Output: 0\n",
      "Input: [5.2, 4.1, 1.5, 0.1] Target: 0.0 Output: 0\n",
      "Input: [5.5, 4.2, 1.4, 0.2] Target: 0.0 Output: 0\n",
      "Input: [4.9, 3.1, 1.5, 0.2] Target: 0.0 Output: 0\n",
      "Input: [5.0, 3.2, 1.2, 0.2] Target: 0.0 Output: 0\n",
      "Input: [5.5, 3.5, 1.3, 0.2] Target: 0.0 Output: 0\n",
      "Input: [4.9, 3.6, 1.4, 0.1] Target: 0.0 Output: 0\n",
      "Input: [4.4, 3.0, 1.3, 0.2] Target: 0.0 Output: 0\n",
      "Input: [5.1, 3.4, 1.5, 0.2] Target: 0.0 Output: 0\n",
      "Input: [5.0, 3.5, 1.3, 0.3] Target: 0.0 Output: 0\n",
      "Input: [4.5, 2.3, 1.3, 0.3] Target: 0.0 Output: 0\n",
      "Input: [4.4, 3.2, 1.3, 0.2] Target: 0.0 Output: 0\n",
      "Input: [5.0, 3.5, 1.6, 0.6] Target: 0.0 Output: 0\n",
      "Input: [5.1, 3.8, 1.9, 0.4] Target: 0.0 Output: 0\n",
      "Input: [4.8, 3.0, 1.4, 0.3] Target: 0.0 Output: 0\n",
      "Input: [5.1, 3.8, 1.6, 0.2] Target: 0.0 Output: 0\n",
      "Input: [4.6, 3.2, 1.4, 0.2] Target: 0.0 Output: 0\n",
      "Input: [5.3, 3.7, 1.5, 0.2] Target: 0.0 Output: 0\n",
      "Input: [5.0, 3.3, 1.4, 0.2] Target: 0.0 Output: 0\n",
      "Input: [7.0, 3.2, 4.7, 1.4] Target: 1.0 Output: 1\n",
      "Input: [6.4, 3.2, 4.5, 1.5] Target: 1.0 Output: 1\n",
      "Input: [6.9, 3.1, 4.9, 1.5] Target: 1.0 Output: 1\n",
      "Input: [5.5, 2.3, 4.0, 1.3] Target: 1.0 Output: 1\n",
      "Input: [6.5, 2.8, 4.6, 1.5] Target: 1.0 Output: 1\n",
      "Input: [5.7, 2.8, 4.5, 1.3] Target: 1.0 Output: 1\n",
      "Input: [6.3, 3.3, 4.7, 1.6] Target: 1.0 Output: 1\n",
      "Input: [4.9, 2.4, 3.3, 1.0] Target: 1.0 Output: 1\n",
      "Input: [6.6, 2.9, 4.6, 1.3] Target: 1.0 Output: 1\n",
      "Input: [5.2, 2.7, 3.9, 1.4] Target: 1.0 Output: 1\n",
      "Input: [5.0, 2.0, 3.5, 1.0] Target: 1.0 Output: 1\n",
      "Input: [5.9, 3.0, 4.2, 1.5] Target: 1.0 Output: 1\n",
      "Input: [6.0, 2.2, 4.0, 1.0] Target: 1.0 Output: 1\n",
      "Input: [6.1, 2.9, 4.7, 1.4] Target: 1.0 Output: 1\n",
      "Input: [5.6, 2.9, 3.6, 1.3] Target: 1.0 Output: 1\n",
      "Input: [6.7, 3.1, 4.4, 1.4] Target: 1.0 Output: 1\n",
      "Input: [5.6, 3.0, 4.5, 1.5] Target: 1.0 Output: 1\n",
      "Input: [5.8, 2.7, 4.1, 1.0] Target: 1.0 Output: 1\n",
      "Input: [6.2, 2.2, 4.5, 1.5] Target: 1.0 Output: 1\n",
      "Input: [5.6, 2.5, 3.9, 1.1] Target: 1.0 Output: 1\n",
      "Input: [5.9, 3.2, 4.8, 1.8] Target: 1.0 Output: 1\n",
      "Input: [6.1, 2.8, 4.0, 1.3] Target: 1.0 Output: 1\n",
      "Input: [6.3, 2.5, 4.9, 1.5] Target: 1.0 Output: 1\n",
      "Input: [6.1, 2.8, 4.7, 1.2] Target: 1.0 Output: 1\n",
      "Input: [6.4, 2.9, 4.3, 1.3] Target: 1.0 Output: 1\n",
      "Input: [6.6, 3.0, 4.4, 1.4] Target: 1.0 Output: 1\n",
      "Input: [6.8, 2.8, 4.8, 1.4] Target: 1.0 Output: 1\n",
      "Input: [6.7, 3.0, 5.0, 1.7] Target: 1.0 Output: 1\n",
      "Input: [6.0, 2.9, 4.5, 1.5] Target: 1.0 Output: 1\n",
      "Input: [5.7, 2.6, 3.5, 1.0] Target: 1.0 Output: 1\n",
      "Input: [5.5, 2.4, 3.8, 1.1] Target: 1.0 Output: 1\n",
      "Input: [5.5, 2.4, 3.7, 1.0] Target: 1.0 Output: 1\n",
      "Input: [5.8, 2.7, 3.9, 1.2] Target: 1.0 Output: 1\n",
      "Input: [6.0, 2.7, 5.1, 1.6] Target: 1.0 Output: 1\n",
      "Input: [5.4, 3.0, 4.5, 1.5] Target: 1.0 Output: 1\n",
      "Input: [6.0, 3.4, 4.5, 1.6] Target: 1.0 Output: 1\n",
      "Input: [6.7, 3.1, 4.7, 1.5] Target: 1.0 Output: 1\n",
      "Input: [6.3, 2.3, 4.4, 1.3] Target: 1.0 Output: 1\n",
      "Input: [5.6, 3.0, 4.1, 1.3] Target: 1.0 Output: 1\n",
      "Input: [5.5, 2.5, 4.0, 1.3] Target: 1.0 Output: 1\n",
      "Input: [5.5, 2.6, 4.4, 1.2] Target: 1.0 Output: 1\n",
      "Input: [6.1, 3.0, 4.6, 1.4] Target: 1.0 Output: 1\n",
      "Input: [5.8, 2.6, 4.0, 1.2] Target: 1.0 Output: 1\n",
      "Input: [5.0, 2.3, 3.3, 1.0] Target: 1.0 Output: 1\n",
      "Input: [5.6, 2.7, 4.2, 1.3] Target: 1.0 Output: 1\n",
      "Input: [5.7, 3.0, 4.2, 1.2] Target: 1.0 Output: 1\n",
      "Input: [5.7, 2.9, 4.2, 1.3] Target: 1.0 Output: 1\n",
      "Input: [6.2, 2.9, 4.3, 1.3] Target: 1.0 Output: 1\n",
      "Input: [5.1, 2.5, 3.0, 1.1] Target: 1.0 Output: 1\n",
      "Input: [5.7, 2.8, 4.1, 1.3] Target: 1.0 Output: 1\n",
      "\n",
      "\n",
      "Classification types Setosa & Versicolour:\n",
      "Weights: [-0.6115769101255014, -0.34158890923117563, 1.092943656131372, 1.0724486268963493], Bias: 0.33429495893821126\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df2 = df[df['target'] != 2]\n",
    "\n",
    "data = []\n",
    "\n",
    "for index, row in df2.iterrows():\n",
    "    data.append(([row['sepal length (cm)'], row['sepal width (cm)'], row['petal length (cm)'], row['petal width (cm)']], row['target']))\n",
    "\n",
    "inputs, target = data[1]\n",
    "    \n",
    "irisPerceptron = Perceptron(weights=[random.uniform(-1, 1) for _ in range(4)], bias=random.uniform(-1, 1))\n",
    "\n",
    "epochs = 1000\n",
    "for i in range(epochs):\n",
    "    for index, row in df2.iterrows():\n",
    "        inputs = [row['sepal length (cm)'], row['sepal width (cm)'], row['petal length (cm)'], row['petal width (cm)']]\n",
    "        target = row['target']\n",
    "        irisPerceptron.update(inputs, target)\n",
    "    mse = irisPerceptron.loss(data)\n",
    "    print(\"MSE on epoch\", str(i+1), str(mse))\n",
    "    if(mse == 0):\n",
    "        print(\"Learned after\", i, \"epochs\")\n",
    "        break\n",
    "\n",
    "# Test the Perceptron on the IRIS data\n",
    "for index, row in df2.iterrows():\n",
    "    inputs = [row['sepal length (cm)'], row['sepal width (cm)'], row['petal length (cm)'], row['petal width (cm)']]\n",
    "    target = row['target']\n",
    "    output = irisPerceptron.activate(inputs)\n",
    "    print(f\"Input: {inputs} Target: {target} Output: {output}\")\n",
    "\n",
    "print(\"\\n\\nClassification types Setosa & Versicolour:\")\n",
    "print(f\"Weights: {irisPerceptron.weights}, Bias: {irisPerceptron.bias}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "83a8ebd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE on epoch 1 0.5\n",
      "MSE on epoch 2 0.5\n",
      "MSE on epoch 3 0.5\n",
      "MSE on epoch 4 0.5\n",
      "MSE on epoch 5 0.5\n",
      "MSE on epoch 6 0.5\n",
      "MSE on epoch 7 0.5\n",
      "MSE on epoch 8 0.5\n",
      "MSE on epoch 9 0.5\n",
      "MSE on epoch 10 0.5\n",
      "MSE on epoch 11 0.5\n",
      "MSE on epoch 12 0.5\n",
      "MSE on epoch 13 0.5\n",
      "MSE on epoch 14 0.5\n",
      "MSE on epoch 15 0.5\n",
      "MSE on epoch 16 0.5\n",
      "MSE on epoch 17 0.5\n",
      "MSE on epoch 18 0.5\n",
      "MSE on epoch 19 0.5\n",
      "MSE on epoch 20 0.5\n",
      "MSE on epoch 21 0.5\n",
      "MSE on epoch 22 0.5\n",
      "MSE on epoch 23 0.5\n",
      "MSE on epoch 24 0.5\n",
      "MSE on epoch 25 0.5\n",
      "MSE on epoch 26 0.5\n",
      "MSE on epoch 27 0.5\n",
      "MSE on epoch 28 0.5\n",
      "MSE on epoch 29 0.5\n",
      "MSE on epoch 30 0.5\n",
      "MSE on epoch 31 0.5\n",
      "MSE on epoch 32 0.5\n",
      "MSE on epoch 33 0.5\n",
      "MSE on epoch 34 0.5\n",
      "MSE on epoch 35 0.5\n",
      "MSE on epoch 36 0.5\n",
      "MSE on epoch 37 0.5\n",
      "MSE on epoch 38 0.5\n",
      "MSE on epoch 39 0.5\n",
      "MSE on epoch 40 0.5\n",
      "MSE on epoch 41 0.5\n",
      "MSE on epoch 42 0.5\n",
      "MSE on epoch 43 0.5\n",
      "MSE on epoch 44 0.5\n",
      "MSE on epoch 45 0.5\n",
      "MSE on epoch 46 0.5\n",
      "MSE on epoch 47 0.5\n",
      "MSE on epoch 48 0.5\n",
      "MSE on epoch 49 0.5\n",
      "MSE on epoch 50 0.5\n",
      "MSE on epoch 51 0.5\n",
      "MSE on epoch 52 0.5\n",
      "MSE on epoch 53 0.5\n",
      "MSE on epoch 54 0.5\n",
      "MSE on epoch 55 0.5\n",
      "MSE on epoch 56 0.5\n",
      "MSE on epoch 57 0.5\n",
      "MSE on epoch 58 0.5\n",
      "MSE on epoch 59 0.5\n",
      "MSE on epoch 60 0.5\n",
      "MSE on epoch 61 0.5\n",
      "MSE on epoch 62 0.5\n",
      "MSE on epoch 63 0.5\n",
      "MSE on epoch 64 0.5\n",
      "MSE on epoch 65 0.5\n",
      "MSE on epoch 66 0.5\n",
      "MSE on epoch 67 0.5\n",
      "MSE on epoch 68 0.5\n",
      "MSE on epoch 69 0.5\n",
      "MSE on epoch 70 0.5\n",
      "MSE on epoch 71 0.5\n",
      "MSE on epoch 72 0.5\n",
      "MSE on epoch 73 0.5\n",
      "MSE on epoch 74 0.5\n",
      "MSE on epoch 75 0.5\n",
      "MSE on epoch 76 0.5\n",
      "MSE on epoch 77 0.5\n",
      "MSE on epoch 78 0.5\n",
      "MSE on epoch 79 0.5\n",
      "MSE on epoch 80 0.5\n",
      "MSE on epoch 81 0.5\n",
      "MSE on epoch 82 0.5\n",
      "MSE on epoch 83 0.5\n",
      "MSE on epoch 84 0.5\n",
      "MSE on epoch 85 0.5\n",
      "MSE on epoch 86 0.5\n",
      "MSE on epoch 87 0.5\n",
      "MSE on epoch 88 0.5\n",
      "MSE on epoch 89 0.5\n",
      "MSE on epoch 90 0.5\n",
      "MSE on epoch 91 0.5\n",
      "MSE on epoch 92 0.5\n",
      "MSE on epoch 93 0.5\n",
      "MSE on epoch 94 0.5\n",
      "MSE on epoch 95 0.5\n",
      "MSE on epoch 96 0.5\n",
      "MSE on epoch 97 0.5\n",
      "MSE on epoch 98 0.5\n",
      "MSE on epoch 99 0.5\n",
      "MSE on epoch 100 0.5\n",
      "MSE on epoch 101 0.5\n",
      "MSE on epoch 102 0.5\n",
      "MSE on epoch 103 0.5\n",
      "MSE on epoch 104 0.5\n",
      "MSE on epoch 105 0.5\n",
      "MSE on epoch 106 0.5\n",
      "MSE on epoch 107 0.5\n",
      "MSE on epoch 108 0.5\n",
      "MSE on epoch 109 0.5\n",
      "MSE on epoch 110 0.5\n",
      "MSE on epoch 111 0.5\n",
      "MSE on epoch 112 0.5\n",
      "MSE on epoch 113 0.5\n",
      "MSE on epoch 114 0.5\n",
      "MSE on epoch 115 0.5\n",
      "MSE on epoch 116 0.5\n",
      "MSE on epoch 117 0.5\n",
      "MSE on epoch 118 0.5\n",
      "MSE on epoch 119 0.5\n",
      "MSE on epoch 120 0.5\n",
      "MSE on epoch 121 0.5\n",
      "MSE on epoch 122 0.5\n",
      "MSE on epoch 123 0.5\n",
      "MSE on epoch 124 0.5\n",
      "MSE on epoch 125 0.5\n",
      "MSE on epoch 126 0.5\n",
      "MSE on epoch 127 0.5\n",
      "MSE on epoch 128 0.5\n",
      "MSE on epoch 129 0.5\n",
      "MSE on epoch 130 0.5\n",
      "MSE on epoch 131 0.5\n",
      "MSE on epoch 132 0.5\n",
      "MSE on epoch 133 0.5\n",
      "MSE on epoch 134 0.5\n",
      "MSE on epoch 135 0.5\n",
      "MSE on epoch 136 0.5\n",
      "MSE on epoch 137 0.5\n",
      "MSE on epoch 138 0.5\n",
      "MSE on epoch 139 0.5\n",
      "MSE on epoch 140 0.5\n",
      "MSE on epoch 141 0.5\n",
      "MSE on epoch 142 0.5\n",
      "MSE on epoch 143 0.5\n",
      "MSE on epoch 144 0.5\n",
      "MSE on epoch 145 0.5\n",
      "MSE on epoch 146 0.5\n",
      "MSE on epoch 147 0.5\n",
      "MSE on epoch 148 0.5\n",
      "MSE on epoch 149 0.5\n",
      "MSE on epoch 150 0.5\n",
      "MSE on epoch 151 0.5\n",
      "MSE on epoch 152 0.5\n",
      "MSE on epoch 153 0.5\n",
      "MSE on epoch 154 0.5\n",
      "MSE on epoch 155 0.5\n",
      "MSE on epoch 156 0.5\n",
      "MSE on epoch 157 0.5\n",
      "MSE on epoch 158 0.5\n",
      "MSE on epoch 159 0.5\n",
      "MSE on epoch 160 0.5\n",
      "MSE on epoch 161 0.5\n",
      "MSE on epoch 162 0.5\n",
      "MSE on epoch 163 0.5\n",
      "MSE on epoch 164 0.5\n",
      "MSE on epoch 165 0.5\n",
      "MSE on epoch 166 0.5\n",
      "MSE on epoch 167 0.5\n",
      "MSE on epoch 168 0.5\n",
      "MSE on epoch 169 0.5\n",
      "MSE on epoch 170 0.5\n",
      "MSE on epoch 171 0.5\n",
      "MSE on epoch 172 0.5\n",
      "MSE on epoch 173 0.5\n",
      "MSE on epoch 174 0.5\n",
      "MSE on epoch 175 0.5\n",
      "MSE on epoch 176 0.5\n",
      "MSE on epoch 177 0.5\n",
      "MSE on epoch 178 0.5\n",
      "MSE on epoch 179 0.5\n",
      "MSE on epoch 180 0.5\n",
      "MSE on epoch 181 0.5\n",
      "MSE on epoch 182 0.5\n",
      "MSE on epoch 183 0.5\n",
      "MSE on epoch 184 0.5\n",
      "MSE on epoch 185 0.5\n",
      "MSE on epoch 186 0.5\n",
      "MSE on epoch 187 0.5\n",
      "MSE on epoch 188 0.5\n",
      "MSE on epoch 189 0.5\n",
      "MSE on epoch 190 0.5\n",
      "MSE on epoch 191 0.5\n",
      "MSE on epoch 192 0.5\n",
      "MSE on epoch 193 0.5\n",
      "MSE on epoch 194 0.5\n",
      "MSE on epoch 195 0.5\n",
      "MSE on epoch 196 0.5\n",
      "MSE on epoch 197 0.5\n",
      "MSE on epoch 198 0.5\n",
      "MSE on epoch 199 0.5\n",
      "MSE on epoch 200 0.5\n",
      "MSE on epoch 201 0.5\n",
      "MSE on epoch 202 0.5\n",
      "MSE on epoch 203 0.5\n",
      "MSE on epoch 204 0.5\n",
      "MSE on epoch 205 0.5\n",
      "MSE on epoch 206 0.5\n",
      "MSE on epoch 207 0.5\n",
      "MSE on epoch 208 0.5\n",
      "MSE on epoch 209 0.5\n",
      "MSE on epoch 210 0.5\n",
      "MSE on epoch 211 0.5\n",
      "MSE on epoch 212 0.5\n",
      "MSE on epoch 213 0.5\n",
      "MSE on epoch 214 0.5\n",
      "MSE on epoch 215 0.5\n",
      "MSE on epoch 216 0.5\n",
      "MSE on epoch 217 0.5\n",
      "MSE on epoch 218 0.5\n",
      "MSE on epoch 219 0.5\n",
      "MSE on epoch 220 0.5\n",
      "MSE on epoch 221 0.5\n",
      "MSE on epoch 222 0.5\n",
      "MSE on epoch 223 0.5\n",
      "MSE on epoch 224 0.5\n",
      "MSE on epoch 225 0.5\n",
      "MSE on epoch 226 0.5\n",
      "MSE on epoch 227 0.5\n",
      "MSE on epoch 228 0.5\n",
      "MSE on epoch 229 0.5\n",
      "MSE on epoch 230 0.5\n",
      "MSE on epoch 231 0.5\n",
      "MSE on epoch 232 0.5\n",
      "MSE on epoch 233 0.5\n",
      "MSE on epoch 234 0.5\n",
      "MSE on epoch 235 0.5\n",
      "MSE on epoch 236 0.5\n",
      "MSE on epoch 237 0.5\n",
      "MSE on epoch 238 0.5\n",
      "MSE on epoch 239 0.5\n",
      "MSE on epoch 240 0.5\n",
      "MSE on epoch 241 0.5\n",
      "MSE on epoch 242 0.5\n",
      "MSE on epoch 243 0.5\n",
      "MSE on epoch 244 0.5\n",
      "MSE on epoch 245 0.5\n",
      "MSE on epoch 246 0.5\n",
      "MSE on epoch 247 0.5\n",
      "MSE on epoch 248 0.5\n",
      "MSE on epoch 249 0.5\n",
      "MSE on epoch 250 0.5\n",
      "MSE on epoch 251 0.5\n",
      "MSE on epoch 252 0.5\n",
      "MSE on epoch 253 0.5\n",
      "MSE on epoch 254 0.5\n",
      "MSE on epoch 255 0.5\n",
      "MSE on epoch 256 0.5\n",
      "MSE on epoch 257 0.5\n",
      "MSE on epoch 258 0.5\n",
      "MSE on epoch 259 0.5\n",
      "MSE on epoch 260 0.5\n",
      "MSE on epoch 261 0.5\n",
      "MSE on epoch 262 0.5\n",
      "MSE on epoch 263 0.5\n",
      "MSE on epoch 264 0.5\n",
      "MSE on epoch 265 0.5\n",
      "MSE on epoch 266 0.5\n",
      "MSE on epoch 267 0.5\n",
      "MSE on epoch 268 0.5\n",
      "MSE on epoch 269 0.5\n",
      "MSE on epoch 270 0.5\n",
      "MSE on epoch 271 0.5\n",
      "MSE on epoch 272 0.5\n",
      "MSE on epoch 273 0.5\n",
      "MSE on epoch 274 0.5\n",
      "MSE on epoch 275 0.5\n",
      "MSE on epoch 276 0.5\n",
      "MSE on epoch 277 0.5\n",
      "MSE on epoch 278 0.5\n",
      "MSE on epoch 279 0.5\n",
      "MSE on epoch 280 0.5\n",
      "MSE on epoch 281 0.5\n",
      "MSE on epoch 282 0.5\n",
      "MSE on epoch 283 0.5\n",
      "MSE on epoch 284 0.5\n",
      "MSE on epoch 285 0.5\n",
      "MSE on epoch 286 0.5\n",
      "MSE on epoch 287 0.5\n",
      "MSE on epoch 288 0.5\n",
      "MSE on epoch 289 0.5\n",
      "MSE on epoch 290 0.5\n",
      "MSE on epoch 291 0.5\n",
      "MSE on epoch 292 0.5\n",
      "MSE on epoch 293 0.5\n",
      "MSE on epoch 294 0.5\n",
      "MSE on epoch 295 0.5\n",
      "MSE on epoch 296 0.5\n",
      "MSE on epoch 297 0.5\n",
      "MSE on epoch 298 0.5\n",
      "MSE on epoch 299 0.5\n",
      "MSE on epoch 300 0.5\n",
      "MSE on epoch 301 0.5\n",
      "MSE on epoch 302 0.5\n",
      "MSE on epoch 303 0.5\n",
      "MSE on epoch 304 0.5\n",
      "MSE on epoch 305 0.5\n",
      "MSE on epoch 306 0.5\n",
      "MSE on epoch 307 0.5\n",
      "MSE on epoch 308 0.5\n",
      "MSE on epoch 309 0.5\n",
      "MSE on epoch 310 0.5\n",
      "MSE on epoch 311 0.5\n",
      "MSE on epoch 312 0.5\n",
      "MSE on epoch 313 0.5\n",
      "MSE on epoch 314 0.5\n",
      "MSE on epoch 315 0.5\n",
      "MSE on epoch 316 0.5\n",
      "MSE on epoch 317 0.5\n",
      "MSE on epoch 318 0.5\n",
      "MSE on epoch 319 0.5\n",
      "MSE on epoch 320 0.5\n",
      "MSE on epoch 321 0.5\n",
      "MSE on epoch 322 0.5\n",
      "MSE on epoch 323 0.5\n",
      "MSE on epoch 324 0.5\n",
      "MSE on epoch 325 0.5\n",
      "MSE on epoch 326 0.5\n",
      "MSE on epoch 327 0.5\n",
      "MSE on epoch 328 0.5\n",
      "MSE on epoch 329 0.5\n",
      "MSE on epoch 330 0.5\n",
      "MSE on epoch 331 0.5\n",
      "MSE on epoch 332 0.5\n",
      "MSE on epoch 333 0.5\n",
      "MSE on epoch 334 0.5\n",
      "MSE on epoch 335 0.5\n",
      "MSE on epoch 336 0.5\n",
      "MSE on epoch 337 0.5\n",
      "MSE on epoch 338 0.5\n",
      "MSE on epoch 339 0.5\n",
      "MSE on epoch 340 0.5\n",
      "MSE on epoch 341 0.5\n",
      "MSE on epoch 342 0.5\n",
      "MSE on epoch 343 0.5\n",
      "MSE on epoch 344 0.5\n",
      "MSE on epoch 345 0.5\n",
      "MSE on epoch 346 0.5\n",
      "MSE on epoch 347 0.5\n",
      "MSE on epoch 348 0.5\n",
      "MSE on epoch 349 0.5\n",
      "MSE on epoch 350 0.5\n",
      "MSE on epoch 351 0.5\n",
      "MSE on epoch 352 0.5\n",
      "MSE on epoch 353 0.5\n",
      "MSE on epoch 354 0.5\n",
      "MSE on epoch 355 0.5\n",
      "MSE on epoch 356 0.5\n",
      "MSE on epoch 357 0.5\n",
      "MSE on epoch 358 0.5\n",
      "MSE on epoch 359 0.5\n",
      "MSE on epoch 360 0.5\n",
      "MSE on epoch 361 0.5\n",
      "MSE on epoch 362 0.5\n",
      "MSE on epoch 363 0.5\n",
      "MSE on epoch 364 0.5\n",
      "MSE on epoch 365 0.5\n",
      "MSE on epoch 366 0.5\n",
      "MSE on epoch 367 0.5\n",
      "MSE on epoch 368 0.5\n",
      "MSE on epoch 369 0.5\n",
      "MSE on epoch 370 0.5\n",
      "MSE on epoch 371 0.5\n",
      "MSE on epoch 372 0.5\n",
      "MSE on epoch 373 0.5\n",
      "MSE on epoch 374 0.5\n",
      "MSE on epoch 375 0.5\n",
      "MSE on epoch 376 0.5\n",
      "MSE on epoch 377 0.5\n",
      "MSE on epoch 378 0.5\n",
      "MSE on epoch 379 0.5\n",
      "MSE on epoch 380 0.5\n",
      "MSE on epoch 381 0.5\n",
      "MSE on epoch 382 0.5\n",
      "MSE on epoch 383 0.5\n",
      "MSE on epoch 384 0.5\n",
      "MSE on epoch 385 0.5\n",
      "MSE on epoch 386 0.5\n",
      "MSE on epoch 387 0.5\n",
      "MSE on epoch 388 0.5\n",
      "MSE on epoch 389 0.5\n",
      "MSE on epoch 390 0.5\n",
      "MSE on epoch 391 0.5\n",
      "MSE on epoch 392 0.5\n",
      "MSE on epoch 393 0.5\n",
      "MSE on epoch 394 0.5\n",
      "MSE on epoch 395 0.5\n",
      "MSE on epoch 396 0.5\n",
      "MSE on epoch 397 0.5\n",
      "MSE on epoch 398 0.5\n",
      "MSE on epoch 399 0.5\n",
      "MSE on epoch 400 0.5\n",
      "MSE on epoch 401 0.5\n",
      "MSE on epoch 402 0.5\n",
      "MSE on epoch 403 0.5\n",
      "MSE on epoch 404 0.5\n",
      "MSE on epoch 405 0.5\n",
      "MSE on epoch 406 0.5\n",
      "MSE on epoch 407 0.5\n",
      "MSE on epoch 408 0.5\n",
      "MSE on epoch 409 0.5\n",
      "MSE on epoch 410 0.5\n",
      "MSE on epoch 411 0.5\n",
      "MSE on epoch 412 0.5\n",
      "MSE on epoch 413 0.5\n",
      "MSE on epoch 414 0.5\n",
      "MSE on epoch 415 0.5\n",
      "MSE on epoch 416 0.5\n",
      "MSE on epoch 417 0.5\n",
      "MSE on epoch 418 0.5\n",
      "MSE on epoch 419 0.5\n",
      "MSE on epoch 420 0.5\n",
      "MSE on epoch 421 0.5\n",
      "MSE on epoch 422 0.5\n",
      "MSE on epoch 423 0.5\n",
      "MSE on epoch 424 0.5\n",
      "MSE on epoch 425 0.5\n",
      "MSE on epoch 426 0.5\n",
      "MSE on epoch 427 0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE on epoch 428 0.5\n",
      "MSE on epoch 429 0.5\n",
      "MSE on epoch 430 0.5\n",
      "MSE on epoch 431 0.5\n",
      "MSE on epoch 432 0.5\n",
      "MSE on epoch 433 0.5\n",
      "MSE on epoch 434 0.5\n",
      "MSE on epoch 435 0.5\n",
      "MSE on epoch 436 0.5\n",
      "MSE on epoch 437 0.5\n",
      "MSE on epoch 438 0.5\n",
      "MSE on epoch 439 0.5\n",
      "MSE on epoch 440 0.5\n",
      "MSE on epoch 441 0.5\n",
      "MSE on epoch 442 0.5\n",
      "MSE on epoch 443 0.5\n",
      "MSE on epoch 444 0.5\n",
      "MSE on epoch 445 0.5\n",
      "MSE on epoch 446 0.5\n",
      "MSE on epoch 447 0.5\n",
      "MSE on epoch 448 0.5\n",
      "MSE on epoch 449 0.5\n",
      "MSE on epoch 450 0.5\n",
      "MSE on epoch 451 0.5\n",
      "MSE on epoch 452 0.5\n",
      "MSE on epoch 453 0.5\n",
      "MSE on epoch 454 0.5\n",
      "MSE on epoch 455 0.5\n",
      "MSE on epoch 456 0.5\n",
      "MSE on epoch 457 0.5\n",
      "MSE on epoch 458 0.5\n",
      "MSE on epoch 459 0.5\n",
      "MSE on epoch 460 0.5\n",
      "MSE on epoch 461 0.5\n",
      "MSE on epoch 462 0.5\n",
      "MSE on epoch 463 0.5\n",
      "MSE on epoch 464 0.5\n",
      "MSE on epoch 465 0.5\n",
      "MSE on epoch 466 0.5\n",
      "MSE on epoch 467 0.5\n",
      "MSE on epoch 468 0.5\n",
      "MSE on epoch 469 0.5\n",
      "MSE on epoch 470 0.5\n",
      "MSE on epoch 471 0.5\n",
      "MSE on epoch 472 0.5\n",
      "MSE on epoch 473 0.5\n",
      "MSE on epoch 474 0.5\n",
      "MSE on epoch 475 0.5\n",
      "MSE on epoch 476 0.5\n",
      "MSE on epoch 477 0.5\n",
      "MSE on epoch 478 0.5\n",
      "MSE on epoch 479 0.5\n",
      "MSE on epoch 480 0.5\n",
      "MSE on epoch 481 0.5\n",
      "MSE on epoch 482 0.5\n",
      "MSE on epoch 483 0.5\n",
      "MSE on epoch 484 0.5\n",
      "MSE on epoch 485 0.5\n",
      "MSE on epoch 486 0.5\n",
      "MSE on epoch 487 0.5\n",
      "MSE on epoch 488 0.5\n",
      "MSE on epoch 489 0.5\n",
      "MSE on epoch 490 0.5\n",
      "MSE on epoch 491 0.5\n",
      "MSE on epoch 492 0.5\n",
      "MSE on epoch 493 0.5\n",
      "MSE on epoch 494 0.5\n",
      "MSE on epoch 495 0.5\n",
      "MSE on epoch 496 0.5\n",
      "MSE on epoch 497 0.5\n",
      "MSE on epoch 498 0.5\n",
      "MSE on epoch 499 0.5\n",
      "MSE on epoch 500 0.5\n",
      "MSE on epoch 501 0.5\n",
      "MSE on epoch 502 0.5\n",
      "MSE on epoch 503 0.5\n",
      "MSE on epoch 504 0.5\n",
      "MSE on epoch 505 0.5\n",
      "MSE on epoch 506 0.5\n",
      "MSE on epoch 507 0.5\n",
      "MSE on epoch 508 0.5\n",
      "MSE on epoch 509 0.5\n",
      "MSE on epoch 510 0.5\n",
      "MSE on epoch 511 0.5\n",
      "MSE on epoch 512 0.5\n",
      "MSE on epoch 513 0.5\n",
      "MSE on epoch 514 0.5\n",
      "MSE on epoch 515 0.5\n",
      "MSE on epoch 516 0.5\n",
      "MSE on epoch 517 0.5\n",
      "MSE on epoch 518 0.5\n",
      "MSE on epoch 519 0.5\n",
      "MSE on epoch 520 0.5\n",
      "MSE on epoch 521 0.5\n",
      "MSE on epoch 522 0.5\n",
      "MSE on epoch 523 0.5\n",
      "MSE on epoch 524 0.5\n",
      "MSE on epoch 525 0.5\n",
      "MSE on epoch 526 0.5\n",
      "MSE on epoch 527 0.5\n",
      "MSE on epoch 528 0.5\n",
      "MSE on epoch 529 0.5\n",
      "MSE on epoch 530 0.5\n",
      "MSE on epoch 531 0.5\n",
      "MSE on epoch 532 0.5\n",
      "MSE on epoch 533 0.5\n",
      "MSE on epoch 534 0.5\n",
      "MSE on epoch 535 0.5\n",
      "MSE on epoch 536 0.5\n",
      "MSE on epoch 537 0.5\n",
      "MSE on epoch 538 0.5\n",
      "MSE on epoch 539 0.5\n",
      "MSE on epoch 540 0.5\n",
      "MSE on epoch 541 0.5\n",
      "MSE on epoch 542 0.5\n",
      "MSE on epoch 543 0.5\n",
      "MSE on epoch 544 0.5\n",
      "MSE on epoch 545 0.5\n",
      "MSE on epoch 546 0.5\n",
      "MSE on epoch 547 0.5\n",
      "MSE on epoch 548 0.5\n",
      "MSE on epoch 549 0.5\n",
      "MSE on epoch 550 0.5\n",
      "MSE on epoch 551 0.5\n",
      "MSE on epoch 552 0.5\n",
      "MSE on epoch 553 0.5\n",
      "MSE on epoch 554 0.5\n",
      "MSE on epoch 555 0.5\n",
      "MSE on epoch 556 0.5\n",
      "MSE on epoch 557 0.5\n",
      "MSE on epoch 558 0.5\n",
      "MSE on epoch 559 0.5\n",
      "MSE on epoch 560 0.5\n",
      "MSE on epoch 561 0.5\n",
      "MSE on epoch 562 0.5\n",
      "MSE on epoch 563 0.5\n",
      "MSE on epoch 564 0.5\n",
      "MSE on epoch 565 0.5\n",
      "MSE on epoch 566 0.5\n",
      "MSE on epoch 567 0.5\n",
      "MSE on epoch 568 0.5\n",
      "MSE on epoch 569 0.5\n",
      "MSE on epoch 570 0.5\n",
      "MSE on epoch 571 0.5\n",
      "MSE on epoch 572 0.5\n",
      "MSE on epoch 573 0.5\n",
      "MSE on epoch 574 0.5\n",
      "MSE on epoch 575 0.5\n",
      "MSE on epoch 576 0.5\n",
      "MSE on epoch 577 0.5\n",
      "MSE on epoch 578 0.5\n",
      "MSE on epoch 579 0.5\n",
      "MSE on epoch 580 0.5\n",
      "MSE on epoch 581 0.5\n",
      "MSE on epoch 582 0.5\n",
      "MSE on epoch 583 0.5\n",
      "MSE on epoch 584 0.5\n",
      "MSE on epoch 585 0.5\n",
      "MSE on epoch 586 0.5\n",
      "MSE on epoch 587 0.5\n",
      "MSE on epoch 588 0.5\n",
      "MSE on epoch 589 0.5\n",
      "MSE on epoch 590 0.5\n",
      "MSE on epoch 591 0.5\n",
      "MSE on epoch 592 0.5\n",
      "MSE on epoch 593 0.5\n",
      "MSE on epoch 594 0.5\n",
      "MSE on epoch 595 0.5\n",
      "MSE on epoch 596 0.5\n",
      "MSE on epoch 597 0.5\n",
      "MSE on epoch 598 0.5\n",
      "MSE on epoch 599 0.5\n",
      "MSE on epoch 600 0.5\n",
      "MSE on epoch 601 0.5\n",
      "MSE on epoch 602 0.5\n",
      "MSE on epoch 603 0.5\n",
      "MSE on epoch 604 0.5\n",
      "MSE on epoch 605 0.5\n",
      "MSE on epoch 606 0.5\n",
      "MSE on epoch 607 0.5\n",
      "MSE on epoch 608 0.5\n",
      "MSE on epoch 609 0.5\n",
      "MSE on epoch 610 0.5\n",
      "MSE on epoch 611 0.5\n",
      "MSE on epoch 612 0.5\n",
      "MSE on epoch 613 0.5\n",
      "MSE on epoch 614 0.5\n",
      "MSE on epoch 615 0.5\n",
      "MSE on epoch 616 0.5\n",
      "MSE on epoch 617 0.5\n",
      "MSE on epoch 618 0.5\n",
      "MSE on epoch 619 0.5\n",
      "MSE on epoch 620 0.5\n",
      "MSE on epoch 621 0.5\n",
      "MSE on epoch 622 0.5\n",
      "MSE on epoch 623 0.5\n",
      "MSE on epoch 624 0.5\n",
      "MSE on epoch 625 0.5\n",
      "MSE on epoch 626 0.5\n",
      "MSE on epoch 627 0.5\n",
      "MSE on epoch 628 0.5\n",
      "MSE on epoch 629 0.5\n",
      "MSE on epoch 630 0.5\n",
      "MSE on epoch 631 0.5\n",
      "MSE on epoch 632 0.5\n",
      "MSE on epoch 633 0.5\n",
      "MSE on epoch 634 0.5\n",
      "MSE on epoch 635 0.5\n",
      "MSE on epoch 636 0.5\n",
      "MSE on epoch 637 0.5\n",
      "MSE on epoch 638 0.5\n",
      "MSE on epoch 639 0.5\n",
      "MSE on epoch 640 0.5\n",
      "MSE on epoch 641 0.5\n",
      "MSE on epoch 642 0.5\n",
      "MSE on epoch 643 0.5\n",
      "MSE on epoch 644 0.5\n",
      "MSE on epoch 645 0.5\n",
      "MSE on epoch 646 0.5\n",
      "MSE on epoch 647 0.5\n",
      "MSE on epoch 648 0.5\n",
      "MSE on epoch 649 0.5\n",
      "MSE on epoch 650 0.5\n",
      "MSE on epoch 651 0.5\n",
      "MSE on epoch 652 0.5\n",
      "MSE on epoch 653 0.5\n",
      "MSE on epoch 654 0.5\n",
      "MSE on epoch 655 0.5\n",
      "MSE on epoch 656 0.5\n",
      "MSE on epoch 657 0.5\n",
      "MSE on epoch 658 0.5\n",
      "MSE on epoch 659 0.5\n",
      "MSE on epoch 660 0.5\n",
      "MSE on epoch 661 0.5\n",
      "MSE on epoch 662 0.5\n",
      "MSE on epoch 663 0.5\n",
      "MSE on epoch 664 0.5\n",
      "MSE on epoch 665 0.5\n",
      "MSE on epoch 666 0.5\n",
      "MSE on epoch 667 0.5\n",
      "MSE on epoch 668 0.5\n",
      "MSE on epoch 669 0.5\n",
      "MSE on epoch 670 0.5\n",
      "MSE on epoch 671 0.5\n",
      "MSE on epoch 672 0.5\n",
      "MSE on epoch 673 0.5\n",
      "MSE on epoch 674 0.5\n",
      "MSE on epoch 675 0.5\n",
      "MSE on epoch 676 0.5\n",
      "MSE on epoch 677 0.5\n",
      "MSE on epoch 678 0.5\n",
      "MSE on epoch 679 0.5\n",
      "MSE on epoch 680 0.5\n",
      "MSE on epoch 681 0.5\n",
      "MSE on epoch 682 0.5\n",
      "MSE on epoch 683 0.5\n",
      "MSE on epoch 684 0.5\n",
      "MSE on epoch 685 0.5\n",
      "MSE on epoch 686 0.5\n",
      "MSE on epoch 687 0.5\n",
      "MSE on epoch 688 0.5\n",
      "MSE on epoch 689 0.5\n",
      "MSE on epoch 690 0.5\n",
      "MSE on epoch 691 0.5\n",
      "MSE on epoch 692 0.5\n",
      "MSE on epoch 693 0.5\n",
      "MSE on epoch 694 0.5\n",
      "MSE on epoch 695 0.5\n",
      "MSE on epoch 696 0.5\n",
      "MSE on epoch 697 0.5\n",
      "MSE on epoch 698 0.5\n",
      "MSE on epoch 699 0.5\n",
      "MSE on epoch 700 0.5\n",
      "MSE on epoch 701 0.5\n",
      "MSE on epoch 702 0.5\n",
      "MSE on epoch 703 0.5\n",
      "MSE on epoch 704 0.5\n",
      "MSE on epoch 705 0.5\n",
      "MSE on epoch 706 0.5\n",
      "MSE on epoch 707 0.5\n",
      "MSE on epoch 708 0.5\n",
      "MSE on epoch 709 0.5\n",
      "MSE on epoch 710 0.5\n",
      "MSE on epoch 711 0.5\n",
      "MSE on epoch 712 0.5\n",
      "MSE on epoch 713 0.5\n",
      "MSE on epoch 714 0.5\n",
      "MSE on epoch 715 0.5\n",
      "MSE on epoch 716 0.5\n",
      "MSE on epoch 717 0.5\n",
      "MSE on epoch 718 0.5\n",
      "MSE on epoch 719 0.5\n",
      "MSE on epoch 720 0.5\n",
      "MSE on epoch 721 0.5\n",
      "MSE on epoch 722 0.5\n",
      "MSE on epoch 723 0.5\n",
      "MSE on epoch 724 0.5\n",
      "MSE on epoch 725 0.5\n",
      "MSE on epoch 726 0.5\n",
      "MSE on epoch 727 0.5\n",
      "MSE on epoch 728 0.5\n",
      "MSE on epoch 729 0.5\n",
      "MSE on epoch 730 0.5\n",
      "MSE on epoch 731 0.5\n",
      "MSE on epoch 732 0.5\n",
      "MSE on epoch 733 0.5\n",
      "MSE on epoch 734 0.5\n",
      "MSE on epoch 735 0.5\n",
      "MSE on epoch 736 0.5\n",
      "MSE on epoch 737 0.5\n",
      "MSE on epoch 738 0.5\n",
      "MSE on epoch 739 0.5\n",
      "MSE on epoch 740 0.5\n",
      "MSE on epoch 741 0.5\n",
      "MSE on epoch 742 0.5\n",
      "MSE on epoch 743 0.5\n",
      "MSE on epoch 744 0.5\n",
      "MSE on epoch 745 0.5\n",
      "MSE on epoch 746 0.5\n",
      "MSE on epoch 747 0.5\n",
      "MSE on epoch 748 0.5\n",
      "MSE on epoch 749 0.5\n",
      "MSE on epoch 750 0.5\n",
      "MSE on epoch 751 0.5\n",
      "MSE on epoch 752 0.5\n",
      "MSE on epoch 753 0.5\n",
      "MSE on epoch 754 0.5\n",
      "MSE on epoch 755 0.5\n",
      "MSE on epoch 756 0.5\n",
      "MSE on epoch 757 0.5\n",
      "MSE on epoch 758 0.5\n",
      "MSE on epoch 759 0.5\n",
      "MSE on epoch 760 0.5\n",
      "MSE on epoch 761 0.5\n",
      "MSE on epoch 762 0.5\n",
      "MSE on epoch 763 0.5\n",
      "MSE on epoch 764 0.5\n",
      "MSE on epoch 765 0.5\n",
      "MSE on epoch 766 0.5\n",
      "MSE on epoch 767 0.5\n",
      "MSE on epoch 768 0.5\n",
      "MSE on epoch 769 0.5\n",
      "MSE on epoch 770 0.5\n",
      "MSE on epoch 771 0.5\n",
      "MSE on epoch 772 0.5\n",
      "MSE on epoch 773 0.5\n",
      "MSE on epoch 774 0.5\n",
      "MSE on epoch 775 0.5\n",
      "MSE on epoch 776 0.5\n",
      "MSE on epoch 777 0.5\n",
      "MSE on epoch 778 0.5\n",
      "MSE on epoch 779 0.5\n",
      "MSE on epoch 780 0.5\n",
      "MSE on epoch 781 0.5\n",
      "MSE on epoch 782 0.5\n",
      "MSE on epoch 783 0.5\n",
      "MSE on epoch 784 0.5\n",
      "MSE on epoch 785 0.5\n",
      "MSE on epoch 786 0.5\n",
      "MSE on epoch 787 0.5\n",
      "MSE on epoch 788 0.5\n",
      "MSE on epoch 789 0.5\n",
      "MSE on epoch 790 0.5\n",
      "MSE on epoch 791 0.5\n",
      "MSE on epoch 792 0.5\n",
      "MSE on epoch 793 0.5\n",
      "MSE on epoch 794 0.5\n",
      "MSE on epoch 795 0.5\n",
      "MSE on epoch 796 0.5\n",
      "MSE on epoch 797 0.5\n",
      "MSE on epoch 798 0.5\n",
      "MSE on epoch 799 0.5\n",
      "MSE on epoch 800 0.5\n",
      "MSE on epoch 801 0.5\n",
      "MSE on epoch 802 0.5\n",
      "MSE on epoch 803 0.5\n",
      "MSE on epoch 804 0.5\n",
      "MSE on epoch 805 0.5\n",
      "MSE on epoch 806 0.5\n",
      "MSE on epoch 807 0.5\n",
      "MSE on epoch 808 0.5\n",
      "MSE on epoch 809 0.5\n",
      "MSE on epoch 810 0.5\n",
      "MSE on epoch 811 0.5\n",
      "MSE on epoch 812 0.5\n",
      "MSE on epoch 813 0.5\n",
      "MSE on epoch 814 0.5\n",
      "MSE on epoch 815 0.5\n",
      "MSE on epoch 816 0.5\n",
      "MSE on epoch 817 0.5\n",
      "MSE on epoch 818 0.5\n",
      "MSE on epoch 819 0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE on epoch 820 0.5\n",
      "MSE on epoch 821 0.5\n",
      "MSE on epoch 822 0.5\n",
      "MSE on epoch 823 0.5\n",
      "MSE on epoch 824 0.5\n",
      "MSE on epoch 825 0.5\n",
      "MSE on epoch 826 0.5\n",
      "MSE on epoch 827 0.5\n",
      "MSE on epoch 828 0.5\n",
      "MSE on epoch 829 0.5\n",
      "MSE on epoch 830 0.5\n",
      "MSE on epoch 831 0.5\n",
      "MSE on epoch 832 0.5\n",
      "MSE on epoch 833 0.5\n",
      "MSE on epoch 834 0.5\n",
      "MSE on epoch 835 0.5\n",
      "MSE on epoch 836 0.5\n",
      "MSE on epoch 837 0.5\n",
      "MSE on epoch 838 0.5\n",
      "MSE on epoch 839 0.5\n",
      "MSE on epoch 840 0.5\n",
      "MSE on epoch 841 0.5\n",
      "MSE on epoch 842 0.5\n",
      "MSE on epoch 843 0.5\n",
      "MSE on epoch 844 0.5\n",
      "MSE on epoch 845 0.5\n",
      "MSE on epoch 846 0.5\n",
      "MSE on epoch 847 0.5\n",
      "MSE on epoch 848 0.5\n",
      "MSE on epoch 849 0.5\n",
      "MSE on epoch 850 0.5\n",
      "MSE on epoch 851 0.5\n",
      "MSE on epoch 852 0.5\n",
      "MSE on epoch 853 0.5\n",
      "MSE on epoch 854 0.5\n",
      "MSE on epoch 855 0.5\n",
      "MSE on epoch 856 0.5\n",
      "MSE on epoch 857 0.5\n",
      "MSE on epoch 858 0.5\n",
      "MSE on epoch 859 0.5\n",
      "MSE on epoch 860 0.5\n",
      "MSE on epoch 861 0.5\n",
      "MSE on epoch 862 0.5\n",
      "MSE on epoch 863 0.5\n",
      "MSE on epoch 864 0.5\n",
      "MSE on epoch 865 0.5\n",
      "MSE on epoch 866 0.5\n",
      "MSE on epoch 867 0.5\n",
      "MSE on epoch 868 0.5\n",
      "MSE on epoch 869 0.5\n",
      "MSE on epoch 870 0.5\n",
      "MSE on epoch 871 0.5\n",
      "MSE on epoch 872 0.5\n",
      "MSE on epoch 873 0.5\n",
      "MSE on epoch 874 0.5\n",
      "MSE on epoch 875 0.5\n",
      "MSE on epoch 876 0.5\n",
      "MSE on epoch 877 0.5\n",
      "MSE on epoch 878 0.5\n",
      "MSE on epoch 879 0.5\n",
      "MSE on epoch 880 0.5\n",
      "MSE on epoch 881 0.5\n",
      "MSE on epoch 882 0.5\n",
      "MSE on epoch 883 0.5\n",
      "MSE on epoch 884 0.5\n",
      "MSE on epoch 885 0.5\n",
      "MSE on epoch 886 0.5\n",
      "MSE on epoch 887 0.5\n",
      "MSE on epoch 888 0.5\n",
      "MSE on epoch 889 0.5\n",
      "MSE on epoch 890 0.5\n",
      "MSE on epoch 891 0.5\n",
      "MSE on epoch 892 0.5\n",
      "MSE on epoch 893 0.5\n",
      "MSE on epoch 894 0.5\n",
      "MSE on epoch 895 0.5\n",
      "MSE on epoch 896 0.5\n",
      "MSE on epoch 897 0.5\n",
      "MSE on epoch 898 0.5\n",
      "MSE on epoch 899 0.5\n",
      "MSE on epoch 900 0.5\n",
      "MSE on epoch 901 0.5\n",
      "MSE on epoch 902 0.5\n",
      "MSE on epoch 903 0.5\n",
      "MSE on epoch 904 0.5\n",
      "MSE on epoch 905 0.5\n",
      "MSE on epoch 906 0.5\n",
      "MSE on epoch 907 0.5\n",
      "MSE on epoch 908 0.5\n",
      "MSE on epoch 909 0.5\n",
      "MSE on epoch 910 0.5\n",
      "MSE on epoch 911 0.5\n",
      "MSE on epoch 912 0.5\n",
      "MSE on epoch 913 0.5\n",
      "MSE on epoch 914 0.5\n",
      "MSE on epoch 915 0.5\n",
      "MSE on epoch 916 0.5\n",
      "MSE on epoch 917 0.5\n",
      "MSE on epoch 918 0.5\n",
      "MSE on epoch 919 0.5\n",
      "MSE on epoch 920 0.5\n",
      "MSE on epoch 921 0.5\n",
      "MSE on epoch 922 0.5\n",
      "MSE on epoch 923 0.5\n",
      "MSE on epoch 924 0.5\n",
      "MSE on epoch 925 0.5\n",
      "MSE on epoch 926 0.5\n",
      "MSE on epoch 927 0.5\n",
      "MSE on epoch 928 0.5\n",
      "MSE on epoch 929 0.5\n",
      "MSE on epoch 930 0.5\n",
      "MSE on epoch 931 0.5\n",
      "MSE on epoch 932 0.5\n",
      "MSE on epoch 933 0.5\n",
      "MSE on epoch 934 0.5\n",
      "MSE on epoch 935 0.5\n",
      "MSE on epoch 936 0.5\n",
      "MSE on epoch 937 0.5\n",
      "MSE on epoch 938 0.5\n",
      "MSE on epoch 939 0.5\n",
      "MSE on epoch 940 0.5\n",
      "MSE on epoch 941 0.5\n",
      "MSE on epoch 942 0.5\n",
      "MSE on epoch 943 0.5\n",
      "MSE on epoch 944 0.5\n",
      "MSE on epoch 945 0.5\n",
      "MSE on epoch 946 0.5\n",
      "MSE on epoch 947 0.5\n",
      "MSE on epoch 948 0.5\n",
      "MSE on epoch 949 0.5\n",
      "MSE on epoch 950 0.5\n",
      "MSE on epoch 951 0.5\n",
      "MSE on epoch 952 0.5\n",
      "MSE on epoch 953 0.5\n",
      "MSE on epoch 954 0.5\n",
      "MSE on epoch 955 0.5\n",
      "MSE on epoch 956 0.5\n",
      "MSE on epoch 957 0.5\n",
      "MSE on epoch 958 0.5\n",
      "MSE on epoch 959 0.5\n",
      "MSE on epoch 960 0.5\n",
      "MSE on epoch 961 0.5\n",
      "MSE on epoch 962 0.5\n",
      "MSE on epoch 963 0.5\n",
      "MSE on epoch 964 0.5\n",
      "MSE on epoch 965 0.5\n",
      "MSE on epoch 966 0.5\n",
      "MSE on epoch 967 0.5\n",
      "MSE on epoch 968 0.5\n",
      "MSE on epoch 969 0.5\n",
      "MSE on epoch 970 0.5\n",
      "MSE on epoch 971 0.5\n",
      "MSE on epoch 972 0.5\n",
      "MSE on epoch 973 0.5\n",
      "MSE on epoch 974 0.5\n",
      "MSE on epoch 975 0.5\n",
      "MSE on epoch 976 0.5\n",
      "MSE on epoch 977 0.5\n",
      "MSE on epoch 978 0.5\n",
      "MSE on epoch 979 0.5\n",
      "MSE on epoch 980 0.5\n",
      "MSE on epoch 981 0.5\n",
      "MSE on epoch 982 0.5\n",
      "MSE on epoch 983 0.5\n",
      "MSE on epoch 984 0.5\n",
      "MSE on epoch 985 0.5\n",
      "MSE on epoch 986 0.5\n",
      "MSE on epoch 987 0.5\n",
      "MSE on epoch 988 0.5\n",
      "MSE on epoch 989 0.5\n",
      "MSE on epoch 990 0.5\n",
      "MSE on epoch 991 0.5\n",
      "MSE on epoch 992 0.5\n",
      "MSE on epoch 993 0.5\n",
      "MSE on epoch 994 0.5\n",
      "MSE on epoch 995 0.5\n",
      "MSE on epoch 996 0.5\n",
      "MSE on epoch 997 0.5\n",
      "MSE on epoch 998 0.5\n",
      "MSE on epoch 999 0.5\n",
      "MSE on epoch 1000 0.5\n",
      "Input: [7.0, 3.2, 4.7, 1.4] Target: 1.0 Output: 1\n",
      "Input: [6.4, 3.2, 4.5, 1.5] Target: 1.0 Output: 1\n",
      "Input: [6.9, 3.1, 4.9, 1.5] Target: 1.0 Output: 1\n",
      "Input: [5.5, 2.3, 4.0, 1.3] Target: 1.0 Output: 1\n",
      "Input: [6.5, 2.8, 4.6, 1.5] Target: 1.0 Output: 1\n",
      "Input: [5.7, 2.8, 4.5, 1.3] Target: 1.0 Output: 1\n",
      "Input: [6.3, 3.3, 4.7, 1.6] Target: 1.0 Output: 1\n",
      "Input: [4.9, 2.4, 3.3, 1.0] Target: 1.0 Output: 1\n",
      "Input: [6.6, 2.9, 4.6, 1.3] Target: 1.0 Output: 1\n",
      "Input: [5.2, 2.7, 3.9, 1.4] Target: 1.0 Output: 1\n",
      "Input: [5.0, 2.0, 3.5, 1.0] Target: 1.0 Output: 1\n",
      "Input: [5.9, 3.0, 4.2, 1.5] Target: 1.0 Output: 1\n",
      "Input: [6.0, 2.2, 4.0, 1.0] Target: 1.0 Output: 1\n",
      "Input: [6.1, 2.9, 4.7, 1.4] Target: 1.0 Output: 1\n",
      "Input: [5.6, 2.9, 3.6, 1.3] Target: 1.0 Output: 1\n",
      "Input: [6.7, 3.1, 4.4, 1.4] Target: 1.0 Output: 1\n",
      "Input: [5.6, 3.0, 4.5, 1.5] Target: 1.0 Output: 1\n",
      "Input: [5.8, 2.7, 4.1, 1.0] Target: 1.0 Output: 1\n",
      "Input: [6.2, 2.2, 4.5, 1.5] Target: 1.0 Output: 1\n",
      "Input: [5.6, 2.5, 3.9, 1.1] Target: 1.0 Output: 1\n",
      "Input: [5.9, 3.2, 4.8, 1.8] Target: 1.0 Output: 1\n",
      "Input: [6.1, 2.8, 4.0, 1.3] Target: 1.0 Output: 1\n",
      "Input: [6.3, 2.5, 4.9, 1.5] Target: 1.0 Output: 1\n",
      "Input: [6.1, 2.8, 4.7, 1.2] Target: 1.0 Output: 1\n",
      "Input: [6.4, 2.9, 4.3, 1.3] Target: 1.0 Output: 1\n",
      "Input: [6.6, 3.0, 4.4, 1.4] Target: 1.0 Output: 1\n",
      "Input: [6.8, 2.8, 4.8, 1.4] Target: 1.0 Output: 1\n",
      "Input: [6.7, 3.0, 5.0, 1.7] Target: 1.0 Output: 1\n",
      "Input: [6.0, 2.9, 4.5, 1.5] Target: 1.0 Output: 1\n",
      "Input: [5.7, 2.6, 3.5, 1.0] Target: 1.0 Output: 1\n",
      "Input: [5.5, 2.4, 3.8, 1.1] Target: 1.0 Output: 1\n",
      "Input: [5.5, 2.4, 3.7, 1.0] Target: 1.0 Output: 1\n",
      "Input: [5.8, 2.7, 3.9, 1.2] Target: 1.0 Output: 1\n",
      "Input: [6.0, 2.7, 5.1, 1.6] Target: 1.0 Output: 1\n",
      "Input: [5.4, 3.0, 4.5, 1.5] Target: 1.0 Output: 1\n",
      "Input: [6.0, 3.4, 4.5, 1.6] Target: 1.0 Output: 1\n",
      "Input: [6.7, 3.1, 4.7, 1.5] Target: 1.0 Output: 1\n",
      "Input: [6.3, 2.3, 4.4, 1.3] Target: 1.0 Output: 1\n",
      "Input: [5.6, 3.0, 4.1, 1.3] Target: 1.0 Output: 1\n",
      "Input: [5.5, 2.5, 4.0, 1.3] Target: 1.0 Output: 1\n",
      "Input: [5.5, 2.6, 4.4, 1.2] Target: 1.0 Output: 1\n",
      "Input: [6.1, 3.0, 4.6, 1.4] Target: 1.0 Output: 1\n",
      "Input: [5.8, 2.6, 4.0, 1.2] Target: 1.0 Output: 1\n",
      "Input: [5.0, 2.3, 3.3, 1.0] Target: 1.0 Output: 1\n",
      "Input: [5.6, 2.7, 4.2, 1.3] Target: 1.0 Output: 1\n",
      "Input: [5.7, 3.0, 4.2, 1.2] Target: 1.0 Output: 1\n",
      "Input: [5.7, 2.9, 4.2, 1.3] Target: 1.0 Output: 1\n",
      "Input: [6.2, 2.9, 4.3, 1.3] Target: 1.0 Output: 1\n",
      "Input: [5.1, 2.5, 3.0, 1.1] Target: 1.0 Output: 1\n",
      "Input: [5.7, 2.8, 4.1, 1.3] Target: 1.0 Output: 1\n",
      "Input: [6.3, 3.3, 6.0, 2.5] Target: 2.0 Output: 1\n",
      "Input: [5.8, 2.7, 5.1, 1.9] Target: 2.0 Output: 1\n",
      "Input: [7.1, 3.0, 5.9, 2.1] Target: 2.0 Output: 1\n",
      "Input: [6.3, 2.9, 5.6, 1.8] Target: 2.0 Output: 1\n",
      "Input: [6.5, 3.0, 5.8, 2.2] Target: 2.0 Output: 1\n",
      "Input: [7.6, 3.0, 6.6, 2.1] Target: 2.0 Output: 1\n",
      "Input: [4.9, 2.5, 4.5, 1.7] Target: 2.0 Output: 1\n",
      "Input: [7.3, 2.9, 6.3, 1.8] Target: 2.0 Output: 1\n",
      "Input: [6.7, 2.5, 5.8, 1.8] Target: 2.0 Output: 1\n",
      "Input: [7.2, 3.6, 6.1, 2.5] Target: 2.0 Output: 1\n",
      "Input: [6.5, 3.2, 5.1, 2.0] Target: 2.0 Output: 1\n",
      "Input: [6.4, 2.7, 5.3, 1.9] Target: 2.0 Output: 1\n",
      "Input: [6.8, 3.0, 5.5, 2.1] Target: 2.0 Output: 1\n",
      "Input: [5.7, 2.5, 5.0, 2.0] Target: 2.0 Output: 1\n",
      "Input: [5.8, 2.8, 5.1, 2.4] Target: 2.0 Output: 1\n",
      "Input: [6.4, 3.2, 5.3, 2.3] Target: 2.0 Output: 1\n",
      "Input: [6.5, 3.0, 5.5, 1.8] Target: 2.0 Output: 1\n",
      "Input: [7.7, 3.8, 6.7, 2.2] Target: 2.0 Output: 1\n",
      "Input: [7.7, 2.6, 6.9, 2.3] Target: 2.0 Output: 1\n",
      "Input: [6.0, 2.2, 5.0, 1.5] Target: 2.0 Output: 1\n",
      "Input: [6.9, 3.2, 5.7, 2.3] Target: 2.0 Output: 1\n",
      "Input: [5.6, 2.8, 4.9, 2.0] Target: 2.0 Output: 1\n",
      "Input: [7.7, 2.8, 6.7, 2.0] Target: 2.0 Output: 1\n",
      "Input: [6.3, 2.7, 4.9, 1.8] Target: 2.0 Output: 1\n",
      "Input: [6.7, 3.3, 5.7, 2.1] Target: 2.0 Output: 1\n",
      "Input: [7.2, 3.2, 6.0, 1.8] Target: 2.0 Output: 1\n",
      "Input: [6.2, 2.8, 4.8, 1.8] Target: 2.0 Output: 1\n",
      "Input: [6.1, 3.0, 4.9, 1.8] Target: 2.0 Output: 1\n",
      "Input: [6.4, 2.8, 5.6, 2.1] Target: 2.0 Output: 1\n",
      "Input: [7.2, 3.0, 5.8, 1.6] Target: 2.0 Output: 1\n",
      "Input: [7.4, 2.8, 6.1, 1.9] Target: 2.0 Output: 1\n",
      "Input: [7.9, 3.8, 6.4, 2.0] Target: 2.0 Output: 1\n",
      "Input: [6.4, 2.8, 5.6, 2.2] Target: 2.0 Output: 1\n",
      "Input: [6.3, 2.8, 5.1, 1.5] Target: 2.0 Output: 1\n",
      "Input: [6.1, 2.6, 5.6, 1.4] Target: 2.0 Output: 1\n",
      "Input: [7.7, 3.0, 6.1, 2.3] Target: 2.0 Output: 1\n",
      "Input: [6.3, 3.4, 5.6, 2.4] Target: 2.0 Output: 1\n",
      "Input: [6.4, 3.1, 5.5, 1.8] Target: 2.0 Output: 1\n",
      "Input: [6.0, 3.0, 4.8, 1.8] Target: 2.0 Output: 1\n",
      "Input: [6.9, 3.1, 5.4, 2.1] Target: 2.0 Output: 1\n",
      "Input: [6.7, 3.1, 5.6, 2.4] Target: 2.0 Output: 1\n",
      "Input: [6.9, 3.1, 5.1, 2.3] Target: 2.0 Output: 1\n",
      "Input: [5.8, 2.7, 5.1, 1.9] Target: 2.0 Output: 1\n",
      "Input: [6.8, 3.2, 5.9, 2.3] Target: 2.0 Output: 1\n",
      "Input: [6.7, 3.3, 5.7, 2.5] Target: 2.0 Output: 1\n",
      "Input: [6.7, 3.0, 5.2, 2.3] Target: 2.0 Output: 1\n",
      "Input: [6.3, 2.5, 5.0, 1.9] Target: 2.0 Output: 1\n",
      "Input: [6.5, 3.0, 5.2, 2.0] Target: 2.0 Output: 1\n",
      "Input: [6.2, 3.4, 5.4, 2.3] Target: 2.0 Output: 1\n",
      "Input: [5.9, 3.0, 5.1, 1.8] Target: 2.0 Output: 1\n",
      "\n",
      "\n",
      "Classification types Setosa & Versicolour:\n",
      "Weights: [32941.34237912843, 14869.353970542263, 27760.227705843503, 10130.419425859049], Bias: 4999.188040437659\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df3 = df[df['target'] != 0]\n",
    "\n",
    "data = []\n",
    "\n",
    "for index, row in df3.iterrows():\n",
    "    data.append(([row['sepal length (cm)'], row['sepal width (cm)'], row['petal length (cm)'], row['petal width (cm)']], row['target']))\n",
    "\n",
    "inputs, target = data[1]\n",
    "    \n",
    "irisPerceptron = Perceptron(weights=[random.uniform(-1, 1) for _ in range(4)], bias=random.uniform(-1, 1))\n",
    "\n",
    "epochs = 1000\n",
    "for i in range(epochs):\n",
    "    for index, row in df3.iterrows():\n",
    "        inputs = [row['sepal length (cm)'], row['sepal width (cm)'], row['petal length (cm)'], row['petal width (cm)']]\n",
    "        target = row['target']\n",
    "        irisPerceptron.update(inputs, target)\n",
    "    mse = irisPerceptron.loss(data)\n",
    "    print(\"MSE on epoch\", str(i+1), str(mse))\n",
    "    if(mse == 0):\n",
    "        print(\"Learned after\", i, \"epochs\")\n",
    "        break\n",
    "\n",
    "# Test the Perceptron on the IRIS data\n",
    "for index, row in df3.iterrows():\n",
    "    inputs = [row['sepal length (cm)'], row['sepal width (cm)'], row['petal length (cm)'], row['petal width (cm)']]\n",
    "    target = row['target']\n",
    "    output = irisPerceptron.activate(inputs)\n",
    "    print(f\"Input: {inputs} Target: {target} Output: {output}\")\n",
    "\n",
    "print(\"\\n\\nClassification types Verginica & Versicolour:\")\n",
    "print(f\"Weights: {irisPerceptron.weights}, Bias: {irisPerceptron.bias}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "9e6492111c66deaf1d2b584bda8444404f0a5e0c368f927779c3f925a3713a54"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
